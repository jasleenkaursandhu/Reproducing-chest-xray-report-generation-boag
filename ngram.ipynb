{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyMOalygsWDI9cktNGMJnn7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasleenkaursandhu/Reproducing-chest-xray-report-generation-boag/blob/main/ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sP0BluOO0DY1"
      },
      "outputs": [],
      "source": [
        "# N-gram Models for Report Generation\n",
        "# This notebook implements 1-gram, 2-gram, and 3-gram language models for chest X-ray report generation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "from collections import defaultdict, Counter\n",
        "import pickle\n",
        "import gzip\n",
        "import random\n",
        "import re\n",
        "import warnings\n",
        "!pip install pydicom\n",
        "import pydicom\n",
        "from time import gmtime, strftime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOX8yrJv0LFn",
        "outputId": "6df8602a-a8c9-44d9-f5b1-82c5cf4271c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/mimic-cxr-project'\n",
        "!mkdir -p {base_path}/data\n",
        "!mkdir -p {base_path}/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WANs5gfU0Rki",
        "outputId": "b895e85a-95c8-4386-9899-49fdd658bfa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the report parser module\n",
        "import sys\n",
        "sys.path.append(f\"{base_path}/modules\")\n",
        "from report_parser import parse_report, MIMIC_RE\n",
        "print(\"Successfully imported report parser module\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Mq-yU00XtS",
        "outputId": "4417a1ff-a03f-42ac-c552-7db8614c8e58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported report parser module\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test data\n",
        "data_dir = os.path.join(base_path, 'data')\n",
        "files_path = os.path.join(base_path, 'files')\n",
        "output_dir = os.path.join(base_path, 'output')\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(data_dir, 'train.tsv'), sep='\\t')\n",
        "test_df = pd.read_csv(os.path.join(data_dir, 'test.tsv'), sep='\\t')\n",
        "\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZKWVShS0bVI",
        "outputId": "50c491ce-3222-4754-e0ce-f4693fa46294"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (2243, 3)\n",
            "Test data shape: (871, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the top 100 neighbors for each test image\n",
        "neighbors_path = os.path.join(output_dir, 'top100_neighbors.pkl')\n",
        "\n",
        "if os.path.exists(neighbors_path):\n",
        "    with open(neighbors_path, 'rb') as f:\n",
        "        neighbors = pickle.load(f)\n",
        "\n",
        "    print(f\"Loaded neighbors for {len(neighbors)} test images\")\n",
        "    print(f\"Sample neighbors for first test image: {list(neighbors.items())[0][1][:5]}...\")\n",
        "else:\n",
        "    print(f\"Warning: Neighbors file not found at {neighbors_path}\")\n",
        "    print(\"Please run the KNN model first to generate the neighbors file.\")\n",
        "    neighbors = {}\n",
        "    for dicom_id in test_df.dicom_id.values:\n",
        "        neighbors[dicom_id] = random.sample(train_df.dicom_id.tolist(), min(100, len(train_df)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wplhnyXG0fja",
        "outputId": "d7edbcca-0268-45df-d098-34740c8a42e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded neighbors for 380 test images\n",
            "Sample neighbors for first test image: ['15a0e62a-ac8edf75-3444949e-35cf275c-b22ee616', '1d00cfa1-29d99da7-c62126a2-18449dbb-6dd404f0', 'fd228853-2df84977-18361e36-f22ccc25-7d9a4046', '350acbc7-85b7cb9f-030eeac1-1e4ff930-a29191a1', '76bdc346-c4561bc4-c75ab157-4fdcde0e-843596ec']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map each dicom to its study_id\n",
        "report_id_column = 'study_id'\n",
        "report_lookup = dict(train_df[['dicom_id', report_id_column]].values)\n",
        "print(f\"Created lookup dictionary for {len(report_lookup)} training images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82hk_03j0poo",
        "outputId": "dbf6da05-e9f0-45da-8fbe-1023d581e1ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created lookup dictionary for 2243 training images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokens for sequence boundaries\n",
        "START = ''\n",
        "END = ''\n",
        "\n",
        "# Function to parse reports for a list of dicom_ids\n",
        "def get_report_tokens(dicom_ids):\n",
        "    \"\"\"Get tokens from reports for a list of dicom_ids\"\"\"\n",
        "    all_reports = []\n",
        "\n",
        "    for dicom_id in dicom_ids:\n",
        "        if dicom_id not in report_lookup:\n",
        "            continue\n",
        "\n",
        "        report_id = report_lookup[dicom_id]\n",
        "\n",
        "        # Get corresponding subject_id\n",
        "        subject_row = train_df[train_df.dicom_id == dicom_id]\n",
        "        if len(subject_row) == 0:\n",
        "            continue\n",
        "\n",
        "        subject_id = subject_row.iloc[0]['subject_id']\n",
        "\n",
        "        # Construct path to the report\n",
        "        subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
        "        subject_dir = f\"p{subject_id}\"\n",
        "        study_dir = f\"s{report_id}\"\n",
        "        report_file = f\"{study_dir}.txt\"\n",
        "        report_path = os.path.join(files_path, subject_prefix, subject_dir, report_file)\n",
        "\n",
        "        # Parse the report\n",
        "        try:\n",
        "            if os.path.exists(report_path):\n",
        "                parsed_report = parse_report(report_path)\n",
        "                if 'findings' in parsed_report:\n",
        "                    # Tokenize the findings text\n",
        "                    toks = parsed_report['findings'].replace('.', ' . ').split()\n",
        "                    all_reports.append(toks)\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    return all_reports"
      ],
      "metadata": {
        "id": "z9qIMiLI0wq_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-gram model implementation\n",
        "def build_1gram_model(dicom_ids):\n",
        "    \"\"\"Build a 1-gram language model from the reports of the given dicom_ids\"\"\"\n",
        "    word_counts = Counter()\n",
        "\n",
        "    reports = get_report_tokens(dicom_ids)\n",
        "    for tokens in reports:\n",
        "        word_counts.update(tokens)\n",
        "        # Add END token for each report\n",
        "        word_counts[END] += 1\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "def generate_with_1gram(dicom_id):\n",
        "    \"\"\"Generate a report using a 1-gram model\"\"\"\n",
        "    if dicom_id not in neighbors:\n",
        "        return \"\"\n",
        "\n",
        "    # Build model from neighbors\n",
        "    nn = neighbors[dicom_id]\n",
        "    word_counts = build_1gram_model(nn)\n",
        "\n",
        "    if not word_counts:\n",
        "        return \"\"\n",
        "\n",
        "    # Generate report\n",
        "    generated_toks = []\n",
        "    current = \"\"\n",
        "\n",
        "    while current != END and len(generated_toks) < 100:\n",
        "        words, counts = zip(*word_counts.items())\n",
        "        total = sum(counts)\n",
        "        P = np.array(counts) / total\n",
        "\n",
        "        next_word = np.random.choice(words, p=P)\n",
        "        if next_word != END:\n",
        "            generated_toks.append(next_word)\n",
        "        current = next_word\n",
        "\n",
        "    return ' '.join(generated_toks)"
      ],
      "metadata": {
        "id": "f_f30cQv01P3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-gram model implementation\n",
        "def build_2gram_model(dicom_ids):\n",
        "    \"\"\"Build a 2-gram language model from the reports of the given dicom_ids\"\"\"\n",
        "    LM = defaultdict(Counter)\n",
        "\n",
        "    reports = get_report_tokens(dicom_ids)\n",
        "    for tokens in reports:\n",
        "        # Add START and END tokens\n",
        "        padded_toks = [START] + tokens + [END]\n",
        "\n",
        "        # Build 2-gram model\n",
        "        for i in range(len(padded_toks) - 1):\n",
        "            context = padded_toks[i]\n",
        "            target = padded_toks[i+1]\n",
        "            LM[context][target] += 1\n",
        "\n",
        "    return LM\n",
        "\n",
        "def generate_with_2gram(dicom_id):\n",
        "    \"\"\"Generate a report using a 2-gram model\"\"\"\n",
        "    if dicom_id not in neighbors:\n",
        "        return \"\"\n",
        "\n",
        "    # Build model from neighbors\n",
        "    nn = neighbors[dicom_id]\n",
        "    LM = build_2gram_model(nn)\n",
        "\n",
        "    if not LM:\n",
        "        return \"\"\n",
        "\n",
        "    # Generate report\n",
        "    generated_toks = [START]\n",
        "    current = generated_toks[-1]\n",
        "\n",
        "    while current != END and len(generated_toks) < 100:\n",
        "        if current not in LM or not LM[current]:\n",
        "            break\n",
        "\n",
        "        words, counts = zip(*LM[current].items())\n",
        "        total = sum(counts)\n",
        "        P = np.array(counts) / total\n",
        "\n",
        "        next_word = np.random.choice(words, p=P)\n",
        "        generated_toks.append(next_word)\n",
        "        current = next_word\n",
        "\n",
        "    # Remove START and END tokens\n",
        "    generated_toks = [t for t in generated_toks if t != START]\n",
        "    if generated_toks and generated_toks[-1] == END:\n",
        "        generated_toks = generated_toks[:-1]\n",
        "\n",
        "    return ' '.join(generated_toks)"
      ],
      "metadata": {
        "id": "mXx2HKrD055T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3-gram model implementation\n",
        "def build_3gram_model(dicom_ids):\n",
        "    \"\"\"Build a 3-gram language model from the reports of the given dicom_ids\"\"\"\n",
        "    LM = defaultdict(Counter)\n",
        "\n",
        "    reports = get_report_tokens(dicom_ids)\n",
        "    for tokens in reports:\n",
        "        # Add START and END tokens\n",
        "        padded_toks = [START, START] + tokens + [END]\n",
        "\n",
        "        # Build 3-gram model\n",
        "        for i in range(len(padded_toks) - 2):\n",
        "            context = (padded_toks[i], padded_toks[i+1])\n",
        "            target = padded_toks[i+2]\n",
        "            LM[context][target] += 1\n",
        "\n",
        "    return LM\n",
        "\n",
        "def generate_with_3gram(dicom_id):\n",
        "    \"\"\"Generate a report using a 3-gram model\"\"\"\n",
        "    if dicom_id not in neighbors:\n",
        "        return \"\"\n",
        "\n",
        "    # Build model from neighbors\n",
        "    nn = neighbors[dicom_id]\n",
        "    LM = build_3gram_model(nn)\n",
        "\n",
        "    if not LM:\n",
        "        return \"\"\n",
        "\n",
        "    # Generate report\n",
        "    generated_toks = [START, START]\n",
        "    current = generated_toks[-1]\n",
        "\n",
        "    while current != END and len(generated_toks) < 100:\n",
        "        context = (generated_toks[-2], generated_toks[-1])\n",
        "        if context not in LM or not LM[context]:\n",
        "            break\n",
        "\n",
        "        words, counts = zip(*LM[context].items())\n",
        "        total = sum(counts)\n",
        "        P = np.array(counts) / total\n",
        "\n",
        "        next_word = np.random.choice(words, p=P)\n",
        "        generated_toks.append(next_word)\n",
        "        current = next_word\n",
        "\n",
        "    # Remove START and END tokens\n",
        "    generated_toks = [t for t in generated_toks if t != START]\n",
        "    if generated_toks and generated_toks[-1] == END:\n",
        "        generated_toks = generated_toks[:-1]\n",
        "\n",
        "    return ' '.join(generated_toks)"
      ],
      "metadata": {
        "id": "l7acpffo09p2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and save reports for a specific n-gram model\n",
        "def run_ngram_generation(n):\n",
        "    \"\"\"Run n-gram generation and save results\"\"\"\n",
        "    if n not in [1, 2, 3]:\n",
        "        print(f\"Error: n must be 1, 2, or 3, got {n}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Generating reports with {n}-gram model...\")\n",
        "\n",
        "    if n == 1:\n",
        "        generator_func = generate_with_1gram\n",
        "    elif n == 2:\n",
        "        generator_func = generate_with_2gram\n",
        "    else:  # n == 3\n",
        "        generator_func = generate_with_3gram\n",
        "\n",
        "    # Generate reports for all test images\n",
        "    generated_reports = {}\n",
        "    for pred_dicom in tqdm.tqdm(test_df.dicom_id.values):\n",
        "        generated_text = generator_func(pred_dicom)\n",
        "        if generated_text:\n",
        "            generated_reports[pred_dicom] = generated_text\n",
        "\n",
        "    print(f\"Generated reports for {len(generated_reports)} test images\")\n",
        "\n",
        "    # Save the generated reports\n",
        "    pred_file = os.path.join(output_dir, f'{n}-gram.tsv')\n",
        "    print(f\"Saving predictions to {pred_file}\")\n",
        "\n",
        "    with open(pred_file, 'w') as f:\n",
        "        print('dicom_id\\tgenerated', file=f)\n",
        "        for dicom_id, generated in sorted(generated_reports.items()):\n",
        "            cleaned_text = generated.replace('\\t', ' ')\n",
        "            print(f'{dicom_id}\\t{cleaned_text}', file=f)\n",
        "\n",
        "    # Display sample reports\n",
        "    sample_count = min(3, len(generated_reports))\n",
        "    sample_dicoms = list(generated_reports.keys())[:sample_count]\n",
        "\n",
        "    for dicom_id in sample_dicoms:\n",
        "        print(f\"\\nSample report for {dicom_id}:\")\n",
        "        report_text = generated_reports[dicom_id]\n",
        "\n",
        "        if len(report_text) > 200:\n",
        "            print(report_text[:200] + \"...\")\n",
        "        else:\n",
        "            print(report_text)\n",
        "\n",
        "    return generated_reports"
      ],
      "metadata": {
        "id": "lhBR88bj1Ai3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-gram model\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "print(\"Starting 1-gram generation\")\n",
        "run_ngram_generation(1)\n",
        "print(\"Finished 1-gram generation\")\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "\n",
        "# 2-gram model\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "print(\"Starting 2-gram generation\")\n",
        "run_ngram_generation(2)\n",
        "print(\"Finished 2-gram generation\")\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "\n",
        "# 3-gram model\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "print(\"Starting 3-gram generation\")\n",
        "run_ngram_generation(3)\n",
        "print(\"Finished 3-gram generation\")\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhT-bgcsEG2X",
        "outputId": "f6ecce96-8c7b-461b-a894-dd9517397ba7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-17 00:06:27\n",
            "Starting 1-gram generation\n",
            "Generating reports with 1-gram model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 871/871 [07:29<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated reports for 0 test images\n",
            "Saving predictions to /content/drive/MyDrive/mimic-cxr-project/output/1-gram.tsv\n",
            "Finished 1-gram generation\n",
            "2025-04-17 00:13:56\n",
            "2025-04-17 00:13:56\n",
            "Starting 2-gram generation\n",
            "Generating reports with 2-gram model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 871/871 [00:24<00:00, 35.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated reports for 0 test images\n",
            "Saving predictions to /content/drive/MyDrive/mimic-cxr-project/output/2-gram.tsv\n",
            "Finished 2-gram generation\n",
            "2025-04-17 00:14:20\n",
            "2025-04-17 00:14:20\n",
            "Starting 3-gram generation\n",
            "Generating reports with 3-gram model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 871/871 [00:27<00:00, 32.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated reports for 0 test images\n",
            "Saving predictions to /content/drive/MyDrive/mimic-cxr-project/output/3-gram.tsv\n",
            "Finished 3-gram generation\n",
            "2025-04-17 00:14:48\n"
          ]
        }
      ]
    }
  ]
}