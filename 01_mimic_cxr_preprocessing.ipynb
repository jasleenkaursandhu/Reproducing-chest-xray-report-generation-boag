{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasleenkaursandhu/Reproducing-chest-xray-report-generation-boag/blob/main/01_mimic_cxr_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkDFueosDuTS",
        "outputId": "f7ed28a7-cccc-473c-b9db-672cbd69f0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries and mount google drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "import gzip\n",
        "import random\n",
        "import re\n",
        "import warnings\n",
        "!pip install pydicom\n",
        "from collections import Counter, defaultdict\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "base_path = '/content/drive/MyDrive/mimic-cxr-project'\n",
        "!mkdir -p {base_path}/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "JwRpcTwtC0PP",
        "outputId": "dd8b0549-75b2-4f15-833c-621d3789bd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images based on record list: 377110\n",
            "Reports based on study list: 227835\n",
            "(377110, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   subject_id  study_id                                      dicom_id  \\\n",
              "0    10000032  50414267  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014   \n",
              "1    10000032  50414267  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962   \n",
              "2    10000032  53189527  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab   \n",
              "3    10000032  53189527  e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c   \n",
              "4    10000032  53911762  68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714   \n",
              "\n",
              "   dicom_is_available  \n",
              "0                True  \n",
              "1                True  \n",
              "2                True  \n",
              "3                True  \n",
              "4                True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b1a05dc-327f-436a-92a0-cccd3e31c156\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>study_id</th>\n",
              "      <th>dicom_id</th>\n",
              "      <th>dicom_is_available</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000032</td>\n",
              "      <td>50414267</td>\n",
              "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000032</td>\n",
              "      <td>50414267</td>\n",
              "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000032</td>\n",
              "      <td>53189527</td>\n",
              "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10000032</td>\n",
              "      <td>53189527</td>\n",
              "      <td>e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10000032</td>\n",
              "      <td>53911762</td>\n",
              "      <td>68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b1a05dc-327f-436a-92a0-cccd3e31c156')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b1a05dc-327f-436a-92a0-cccd3e31c156 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b1a05dc-327f-436a-92a0-cccd3e31c156');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e42525d-7432-472d-9b4b-a61b3d859782\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e42525d-7432-472d-9b4b-a61b3d859782')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e42525d-7432-472d-9b4b-a61b3d859782 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print('unique   dicoms: %6d' % len(set(df['dicom_id'])))\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"subject_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10000032,\n        \"max\": 10000032,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10000032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"study_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1678041,\n        \"min\": 50414267,\n        \"max\": 53911762,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          50414267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dicom_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dicom_is_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique subjects:  65379\n",
            "unique studies: 227835\n",
            "unique   dicoms: 377110\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data shapes\n",
        "record_list_path = os.path.join(base_path, 'cxr-record-list.csv')\n",
        "study_list_path = os.path.join(base_path, 'cxr-study-list.csv')\n",
        "\n",
        "# Load the CSV files\n",
        "df_studies = pd.read_csv(study_list_path)\n",
        "df_records = pd.read_csv(record_list_path)\n",
        "\n",
        "# Print the counts from these files\n",
        "print('Images based on record list: %6d' % len(df_records))\n",
        "print('Reports based on study list: %6d' % len(df_studies))\n",
        "\n",
        "# Merge them to create a single dataframe with the columns we need\n",
        "df = pd.merge(\n",
        "    df_studies[['subject_id', 'study_id']],\n",
        "    df_records[['subject_id', 'study_id', 'dicom_id']],\n",
        "    on=['subject_id', 'study_id']\n",
        ")\n",
        "\n",
        "# Add dicom_is_available column\n",
        "df['dicom_is_available'] = True\n",
        "\n",
        "print(df.shape)\n",
        "display(df.head())\n",
        "\n",
        "print('unique subjects: %6d' % len(set(df['subject_id'])))\n",
        "print('unique studies: %6d' % len(set(df['study_id'])))\n",
        "print('unique   dicoms: %6d' % len(set(df['dicom_id'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juEO4H9YG7GZ"
      },
      "outputs": [],
      "source": [
        "# Implementing report parser\n",
        "import re\n",
        "\n",
        "class MIMIC_RE(object):\n",
        "    def __init__(self):\n",
        "        self._cached = {}\n",
        "\n",
        "    def get(self, pattern, flags=0):\n",
        "        key = hash((pattern, flags))\n",
        "        if key not in self._cached:\n",
        "            self._cached[key] = re.compile(pattern, flags=flags)\n",
        "\n",
        "        return self._cached[key]\n",
        "\n",
        "    def sub(self, pattern, repl, string, flags=0):\n",
        "        return self.get(pattern, flags=flags).sub(repl, string)\n",
        "\n",
        "    def rm(self, pattern, string, flags=0):\n",
        "        return self.sub(pattern, '', string)\n",
        "\n",
        "    def get_id(self, tag, flags=0):\n",
        "        return self.get(r'\\[\\*\\*.*{:s}.*?\\*\\*\\]'.format(tag), flags=flags)\n",
        "\n",
        "    def sub_id(self, tag, repl, string, flags=0):\n",
        "        return self.get_id(tag).sub(repl, string)\n",
        "\n",
        "def parse_report(path):\n",
        "    mimic_re = MIMIC_RE()\n",
        "    with open(path,'r') as f:\n",
        "        report = f.read()\n",
        "    report = report.lower()\n",
        "    report = mimic_re.sub_id(r'(?:location|address|university|country|state|unit number)', 'LOC', report)\n",
        "    report = mimic_re.sub_id(r'(?:year|month|day|date)', 'DATE', report)\n",
        "    report = mimic_re.sub_id(r'(?:hospital)', 'HOSPITAL', report)\n",
        "    report = mimic_re.sub_id(r'(?:identifier|serial number|medical record number|social security number|md number)', 'ID', report)\n",
        "    report = mimic_re.sub_id(r'(?:age)', 'AGE', report)\n",
        "    report = mimic_re.sub_id(r'(?:phone|pager number|contact info|provider number)', 'PHONE', report)\n",
        "    report = mimic_re.sub_id(r'(?:name|initial|dictator|attending)', 'NAME', report)\n",
        "    report = mimic_re.sub_id(r'(?:company)', 'COMPANY', report)\n",
        "    report = mimic_re.sub_id(r'(?:clip number)', 'CLIP_NUM', report)\n",
        "\n",
        "    report = mimic_re.sub((\n",
        "        r'\\[\\*\\*(?:'\n",
        "            r'\\d{4}'  # 1970\n",
        "            r'|\\d{0,2}[/-]\\d{0,2}'  # 01-01\n",
        "            r'|\\d{0,2}[/-]\\d{4}'  # 01-1970\n",
        "            r'|\\d{0,2}[/-]\\d{0,2}[/-]\\d{4}'  # 01-01-1970\n",
        "            r'|\\d{4}[/-]\\d{0,2}[/-]\\d{0,2}'  # 1970-01-01\n",
        "        r')\\*\\*\\]'\n",
        "    ), 'DATE', report)\n",
        "    report = mimic_re.sub(r'\\[\\*\\*.*\\*\\*\\]', 'OTHER', report)\n",
        "    report = mimic_re.sub(r'(?:\\d{1,2}:\\d{2})', 'TIME', report)\n",
        "\n",
        "    report = mimic_re.rm(r'_{2,}', report, flags=re.MULTILINE)\n",
        "    report = mimic_re.rm(r'the study and the report were reviewed by the staff radiologist.', report)\n",
        "\n",
        "\n",
        "    matches = list(mimic_re.get(r'^(?P<title>[ \\w()]+):', flags=re.MULTILINE).finditer(report))\n",
        "    parsed_report = {}\n",
        "    for (match, next_match) in zip(matches, matches[1:] + [None]):\n",
        "        start = match.end()\n",
        "        end = next_match and next_match.start()\n",
        "\n",
        "        title = match.group('title')\n",
        "        title = title.strip()\n",
        "\n",
        "        paragraph = report[start:end]\n",
        "        paragraph = mimic_re.sub(r'\\s{2,}', ' ', paragraph)\n",
        "        paragraph = paragraph.strip()\n",
        "\n",
        "        parsed_report[title] = paragraph.replace('\\n', '\\\\n')\n",
        "\n",
        "    return parsed_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ypdSNlJPmsr",
        "outputId": "0e3f3d5c-98c7-4138-d320-80aab8655c16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 377110/377110 [7:13:38<00:00, 14.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted view positions for 8363 images\n",
            "\n",
            "View position distribution:\n",
            "AP         8206\n",
            "             58\n",
            "PA           35\n",
            "LATERAL      33\n",
            "LL           31\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Extracting view positions\n",
        "import pydicom\n",
        "import gzip\n",
        "import tqdm\n",
        "\n",
        "# Initialize positions dictionary\n",
        "positions = {}\n",
        "\n",
        "# Get column names\n",
        "columns = df.columns\n",
        "\n",
        "# Process all rows in the dataframe - using the full dataset\n",
        "for vals in tqdm.tqdm(df.values):\n",
        "    row = dict(zip(columns, vals))\n",
        "    dicom_file = str(row['dicom_id']) + '.dcm'\n",
        "\n",
        "    # Construct paths based on your file structure\n",
        "    subject_id = row['subject_id']\n",
        "    subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
        "    subject_dir = f\"p{subject_id}\"\n",
        "    study_id = row['study_id']\n",
        "    study_dir = f\"s{study_id}\"\n",
        "\n",
        "    # Full path to the DICOM file\n",
        "    dicom_path = os.path.join(base_path, 'files', subject_prefix, subject_dir, study_dir, dicom_file)\n",
        "\n",
        "    # Check if file exists\n",
        "    if os.path.exists(dicom_path):\n",
        "        try:\n",
        "            plan = pydicom.dcmread(dicom_path, stop_before_pixels=True)\n",
        "            if hasattr(plan, 'ViewPosition'):\n",
        "                view_position = plan.ViewPosition\n",
        "                positions[row['dicom_id']] = view_position\n",
        "        except Exception as e:\n",
        "            # Just continue without printing errors to avoid cluttering output\n",
        "            pass\n",
        "\n",
        "# Save view positions\n",
        "view_positions_path = os.path.join(base_path, 'view_positions.pkl')\n",
        "with open(view_positions_path, 'wb') as f:\n",
        "    pickle.dump(positions, f)\n",
        "\n",
        "print(f\"Extracted view positions for {len(positions)} images\")\n",
        "\n",
        "# View position distribution\n",
        "position_counts = pd.Series(positions.values()).value_counts()\n",
        "print(\"\\nView position distribution:\")\n",
        "print(position_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ULRm5nSGKjq",
        "outputId": "426c501e-b9f9-47f5-8918-cfddc66a5f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 8363 view positions\n",
            "Sample view positions: {'68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714': 'AP', 'fffabebf-74fd3a1f-673b6b41-96ec0ac9-2ab69818': 'AP'}\n"
          ]
        }
      ],
      "source": [
        "# Load the view positions we saved earlier\n",
        "view_positions_path = os.path.join(base_path, 'view_positions.pkl')\n",
        "with open(view_positions_path, 'rb') as f:\n",
        "    view_positions = pickle.load(f)\n",
        "\n",
        "print(f\"Loaded {len(view_positions)} view positions\")\n",
        "print(\"Sample view positions:\", dict(list(view_positions.items())[:2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMVcr6tqGSh6",
        "outputId": "a5651535-8cd2-4f51-930c-79ae4a196c5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/377110 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# Build dataset of (image, report) pairs organized by patient\n",
        "data = defaultdict(list)\n",
        "\n",
        "# Process rows to find AP images with reports\n",
        "columns = df.columns\n",
        "for vals in tqdm.tqdm(df.values):\n",
        "    row = dict(zip(columns, vals))\n",
        "\n",
        "    # Construct paths\n",
        "    subject_id = row['subject_id']\n",
        "    subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
        "    subject_dir = f\"p{subject_id}\"\n",
        "    study_id = row['study_id']\n",
        "    study_dir = f\"s{study_id}\"\n",
        "\n",
        "    dicom_file = f\"{row['dicom_id']}.dcm\"\n",
        "    dicom_path = os.path.join(base_path, 'files', subject_prefix, subject_dir, study_dir, dicom_file)\n",
        "\n",
        "    report_file = f\"{study_dir}.txt\"\n",
        "    report_path = os.path.join(base_path, 'files', subject_prefix, subject_dir, report_file)\n",
        "\n",
        "    # Check if files exist\n",
        "    if not os.path.exists(dicom_path) or not os.path.exists(report_path):\n",
        "        continue\n",
        "\n",
        "    # Only AP images\n",
        "    dicom_id = row['dicom_id']\n",
        "    if dicom_id not in view_positions or view_positions[dicom_id] != 'AP':\n",
        "        continue\n",
        "\n",
        "    # Check if report has findings section\n",
        "    try:\n",
        "        with open(report_path, 'r') as f:\n",
        "            report_text = f.read().lower()\n",
        "        if 'findings' in report_text:\n",
        "            item = (dicom_path, report_path)\n",
        "            data[row['subject_id']].append(item)\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "print(f\"Built dataset with {len(data)} patients\")\n",
        "print(f\"Total image-report pairs: {sum(len(items) for items in data.values())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOXff3SKIhtv"
      },
      "outputs": [],
      "source": [
        "# List of unique dicom IDs\n",
        "dicom_ids = set()\n",
        "for subject_id, items in list(data.items()):\n",
        "    for dicom_path, report_path in items:\n",
        "        dicom_id = os.path.basename(dicom_path).split('.')[0]\n",
        "        dicom_ids.add(dicom_id)\n",
        "\n",
        "print(f\"Found {len(dicom_ids)} unique DICOM IDs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "aAE5sd78IkmH",
        "outputId": "83bdcbbc-bb5d-4ece-c9f9-0df67c43a1c5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a5aa5baa835d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# List of subject IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubject_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create train/test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubject_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "# List of subject IDs\n",
        "subject_ids = list(data.keys())\n",
        "\n",
        "# Create train/test split\n",
        "subject_ids = list(subject_ids)  # Create a copy\n",
        "random.shuffle(subject_ids)  # Shuffle randomly\n",
        "\n",
        "n = len(subject_ids)\n",
        "split_ind = int(0.7 * n)  # 70% training, 30% testing\n",
        "train_ids = subject_ids[:split_ind]\n",
        "test_ids = subject_ids[split_ind:]\n",
        "\n",
        "print('Train subjects:', len(train_ids))\n",
        "print('Test subjects:', len(test_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "C2JKM-J6IoOF",
        "outputId": "a8b2350a-863b-4151-bf90-5459f809e1ab"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_ids' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d489b2238ff4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msubject_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_ids' is not defined"
          ]
        }
      ],
      "source": [
        "# Check how many images are in each split\n",
        "train_images = 0\n",
        "test_images = 0\n",
        "\n",
        "for subject_id in train_ids:\n",
        "    train_images += len(data[subject_id])\n",
        "\n",
        "for subject_id in test_ids:\n",
        "    test_images += len(data[subject_id])\n",
        "\n",
        "print(f\"Train images: {train_images}\")\n",
        "print(f\"Test images: {test_images}\")\n",
        "print(f\"Total images: {train_images + test_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZmqsWadIuh4"
      },
      "outputs": [],
      "source": [
        "# Create dataframes for train/test sets\n",
        "train_rows = []\n",
        "for subject_id in train_ids:\n",
        "    for dicom_path, report_path in data[subject_id]:\n",
        "        dicom_id = os.path.basename(dicom_path).split('.')[0]\n",
        "        study_id = os.path.basename(os.path.dirname(dicom_path))\n",
        "        train_rows.append({\n",
        "            'subject_id': subject_id,\n",
        "            'study_id': study_id.replace('s', ''),  # Remove the 's' prefix\n",
        "            'dicom_id': dicom_id\n",
        "        })\n",
        "\n",
        "test_rows = []\n",
        "for subject_id in test_ids:\n",
        "    for dicom_path, report_path in data[subject_id]:\n",
        "        dicom_id = os.path.basename(dicom_path).split('.')[0]\n",
        "        study_id = os.path.basename(os.path.dirname(dicom_path))\n",
        "        test_rows.append({\n",
        "            'subject_id': subject_id,\n",
        "            'study_id': study_id.replace('s', ''),  # Remove the 's' prefix\n",
        "            'dicom_id': dicom_id\n",
        "        })\n",
        "\n",
        "train_df = pd.DataFrame(train_rows)\n",
        "test_df = pd.DataFrame(test_rows)\n",
        "\n",
        "# Write to file\n",
        "train_df.to_csv(os.path.join(base_path, 'data', 'train.tsv'), sep='\\t', index=False)\n",
        "test_df.to_csv(os.path.join(base_path, 'data', 'test.tsv'), sep='\\t', index=False)\n",
        "\n",
        "print(f\"Saved {len(train_df)} training samples to data/train.tsv\")\n",
        "print(f\"Saved {len(test_df)} test samples to data/test.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgGYld2eIw0K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "555eaeba-fa28-4afe-b23b-2f775a76fc29"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-72a4a39fc344>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load a few images to spot check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfirst_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirst_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "# Load a few images to spot check\n",
        "n = min(3, len(data))\n",
        "first_n = dict(list(data.items())[:n])\n",
        "\n",
        "for subject_id, items in first_n.items():\n",
        "    print(f'{subject_id} ({len(items)})')\n",
        "\n",
        "    for j, (dicom_path, report_path) in enumerate(items[:2]):  # Show up to 2 images per patient\n",
        "        try:\n",
        "            # Read DICOM file\n",
        "            plan = pydicom.dcmread(dicom_path)\n",
        "\n",
        "            # Convert to image\n",
        "            pixel_array = plan.pixel_array\n",
        "            image = Image.fromarray(np.uint8(pixel_array/pixel_array.max()*255))\n",
        "\n",
        "            # Parse report\n",
        "            parsed_report = parse_report(report_path)\n",
        "\n",
        "            # Display information\n",
        "            print('\\t-----------')\n",
        "            print('\\tPatient ID:', plan.PatientID if hasattr(plan, 'PatientID') else 'Unknown')\n",
        "            print('\\tView Position:', plan.ViewPosition if hasattr(plan, 'ViewPosition') else 'Unknown')\n",
        "\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            if 'findings' in parsed_report:\n",
        "                print(\"\\tFindings:\", parsed_report['findings'])\n",
        "            else:\n",
        "                print('\\tFindings: None')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\tError processing {dicom_path}: {e}\")\n",
        "\n",
        "    print('\\t===================================================')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-zYvIgm0U1y"
      },
      "outputs": [],
      "source": [
        "# Random Baseline Implementation\n",
        "print(\"Implementing Random Baseline Model\")\n",
        "\n",
        "# Train/test data should already be available from previous cells\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "# Map each dicom to its corresponding report identifier\n",
        "# Adjust column names based on your data structure\n",
        "report_id_column = 'study_id'  # This might be 'rad_id' or 'study_id' depending on your data\n",
        "if report_id_column in train_df.columns:\n",
        "    report_lookup = dict(train_df[['dicom_id', report_id_column]].values)\n",
        "    print(f\"Created lookup using {report_id_column}\")\n",
        "else:\n",
        "    print(f\"Warning: {report_id_column} not found in columns: {train_df.columns.tolist()}\")\n",
        "    report_lookup = {}\n",
        "\n",
        "print(\"Sample of lookup dictionary:\")\n",
        "print(dict(list(report_lookup.items())[:5]))\n",
        "\n",
        "# Generate random reports for each test image\n",
        "generated_reports = {}\n",
        "\n",
        "for pred_dicom in tqdm.tqdm(test_df.dicom_id.values):\n",
        "    found = False\n",
        "    attempts = 0\n",
        "    max_attempts = 100  # Limit attempts to avoid infinite loops\n",
        "\n",
        "    while not found and attempts < max_attempts:\n",
        "        attempts += 1\n",
        "\n",
        "        # Randomly select a training image\n",
        "        nearest_dicom = random.choice(train_df.dicom_id.values)\n",
        "\n",
        "        if nearest_dicom not in report_lookup:\n",
        "            continue\n",
        "\n",
        "        report_id = report_lookup[nearest_dicom]\n",
        "\n",
        "        # Get corresponding subject_id\n",
        "        subject_row = train_df[train_df.dicom_id == nearest_dicom]\n",
        "        if len(subject_row) == 0:\n",
        "            continue\n",
        "\n",
        "        subject_id = subject_row.iloc[0]['subject_id']\n",
        "\n",
        "        # Construct path to the report\n",
        "        subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
        "        subject_dir = f\"p{subject_id}\"\n",
        "        study_dir = f\"s{report_id}\"\n",
        "        report_file = f\"{study_dir}.txt\"\n",
        "        report_path = os.path.join(files_path, subject_prefix, subject_dir, report_file)\n",
        "\n",
        "        # Parse the report to extract sections\n",
        "        try:\n",
        "            if os.path.exists(report_path):\n",
        "                report = parse_report(report_path)\n",
        "\n",
        "                # If the report has a findings section, use it\n",
        "                if 'findings' in report:\n",
        "                    found = True\n",
        "                    generated_reports[pred_dicom] = report['findings']\n",
        "        except Exception as e:\n",
        "            # Skip this report and try another\n",
        "            continue\n",
        "\n",
        "    if not found:\n",
        "        print(f\"Warning: Could not find a valid report for {pred_dicom} after {max_attempts} attempts\")\n",
        "\n",
        "print(f\"Generated random reports for {len(generated_reports)}/{len(test_df)} test images\")\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "pred_dir = os.path.join(base_path, 'output')\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "# Save the generated reports to a TSV file\n",
        "pred_file = os.path.join(pred_dir, 'random.tsv')\n",
        "print(f\"Saving predictions to {pred_file}\")\n",
        "\n",
        "with open(pred_file, 'w') as f:\n",
        "    print('dicom_id\\tgenerated', file=f)\n",
        "    for dicom_id, generated in sorted(generated_reports.items()):\n",
        "        # Escape any tab characters in the generated text\n",
        "        cleaned_text = generated.replace('\\t', ' ')\n",
        "        print(f'{dicom_id}\\t{cleaned_text}', file=f)\n",
        "\n",
        "print(f\"Saved random baseline predictions to {pred_file}\")\n",
        "print(f\"Current time: {strftime('%Y-%m-%d %H:%M:%S', gmtime())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuHzGvDCzh8O",
        "outputId": "491baa92-c681-4d77-8e83-da3f861237a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementing N-gram Model\n",
            "Train data shape: (824, 3)\n",
            "Test data shape: (382, 3)\n",
            "Loaded neighbors for 380 test images\n",
            "Sample neighbors for first test image: ['15a0e62a-ac8edf75-3444949e-35cf275c-b22ee616', '1d00cfa1-29d99da7-c62126a2-18449dbb-6dd404f0', 'fd228853-2df84977-18361e36-f22ccc25-7d9a4046', '350acbc7-85b7cb9f-030eeac1-1e4ff930-a29191a1', '76bdc346-c4561bc4-c75ab157-4fdcde0e-843596ec']...\n",
            "Created lookup dictionary for 824 training images\n"
          ]
        }
      ],
      "source": [
        "# N-gram Model Implementation\n",
        "print(\"Implementing N-gram Model\")\n",
        "\n",
        "# Define paths if they're not already defined\n",
        "base_path = '/content/drive/MyDrive/mimic-cxr-project'\n",
        "data_dir = os.path.join(base_path, 'data')\n",
        "files_path = os.path.join(base_path, 'files')\n",
        "output_dir = os.path.join(base_path, 'output')\n",
        "\n",
        "# Load train and test data\n",
        "train_df = pd.read_csv(os.path.join(data_dir, 'train.tsv'), sep='\\t')\n",
        "test_df = pd.read_csv(os.path.join(data_dir, 'test.tsv'), sep='\\t')\n",
        "\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "# Load the top 100 neighbors for each test image\n",
        "# We've already generated this in extract_densenet_features.ipynb\n",
        "neighbors_path = os.path.join(output_dir, 'top100_neighbors.pkl')\n",
        "with open(neighbors_path, 'rb') as f:\n",
        "    neighbors = pickle.load(f)\n",
        "\n",
        "print(f\"Loaded neighbors for {len(neighbors)} test images\")\n",
        "print(f\"Sample neighbors for first test image: {list(neighbors.items())[0][1][:5]}...\")\n",
        "\n",
        "# Map each dicom to its study_id\n",
        "report_id_column = 'study_id'\n",
        "report_lookup = dict(train_df[['dicom_id', report_id_column]].values)\n",
        "print(f\"Created lookup dictionary for {len(report_lookup)} training images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcFloYluOS6R"
      },
      "outputs": [],
      "source": [
        "# Define tokens for sequence boundaries\n",
        "START = '<START>'\n",
        "END = '<END>'\n",
        "\n",
        "# Build n-gram language model from neighbors\n",
        "def fit(dicom_ids, n=3):\n",
        "    \"\"\"Build language model from the reports of the given dicom_ids\"\"\"\n",
        "    # Language model maps context (n-1 previous words) to possible next words\n",
        "    LM = defaultdict(Counter)\n",
        "\n",
        "    for dicom_id in dicom_ids:\n",
        "        if dicom_id not in report_lookup:\n",
        "            continue\n",
        "\n",
        "        report_id = report_lookup[dicom_id]\n",
        "\n",
        "        # Get corresponding subject_id\n",
        "        subject_row = train_df[train_df.dicom_id == dicom_id]\n",
        "        if len(subject_row) == 0:\n",
        "            continue\n",
        "\n",
        "        subject_id = subject_row.iloc[0]['subject_id']\n",
        "\n",
        "        # Construct path to the report\n",
        "        subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
        "        subject_dir = f\"p{subject_id}\"\n",
        "        study_dir = f\"s{report_id}\"\n",
        "        report_file = f\"{study_dir}.txt\"\n",
        "        report_path = os.path.join(files_path, subject_prefix, subject_dir, report_file)\n",
        "\n",
        "        # Parse the report\n",
        "        try:\n",
        "            if os.path.exists(report_path):\n",
        "                parsed_report = parse_report(report_path)\n",
        "\n",
        "                if 'findings' in parsed_report:\n",
        "                    # Tokenize the findings text\n",
        "                    toks = parsed_report['findings'].replace('.', ' . ').split()\n",
        "\n",
        "                    # Add padding tokens at the beginning and END token at the end\n",
        "                    padded_toks = [START for _ in range(n-1)] + toks + [END]\n",
        "\n",
        "                    # Build n-gram model by counting follow words for each context\n",
        "                    for i in range(len(padded_toks) - n + 1):\n",
        "                        context = tuple(padded_toks[i:i+n-1])\n",
        "                        target = padded_toks[i+n-1]\n",
        "                        sim = 1\n",
        "                        LM[context][target] += sim\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    return LM\n",
        "\n",
        "# Sample from the n-gram model\n",
        "def sample(LM, seq_so_far, n):\n",
        "    \"\"\"Sample the next word based on the n-gram language model\"\"\"\n",
        "    last = tuple(seq_so_far[-(n-1):])\n",
        "\n",
        "    if last not in LM or not LM[last]:\n",
        "        # If context not found in model, return END token\n",
        "        return END\n",
        "\n",
        "    words, counts = zip(*LM[last].items())\n",
        "    total = sum(counts)\n",
        "    P = np.array(counts) / total\n",
        "\n",
        "    # Sample next word based on probabilities\n",
        "    choice = np.random.choice(words, p=P)\n",
        "    return choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMSyctUl004g",
        "outputId": "c8435d76-ab58-4dc8-d6ce-e3099f1a2ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating reports with 3-gram model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 43/382 [07:21<08:55,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No neighbors for 7f7346e9-c1f9639f-8e83f5bc-f166c421-69f3b162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 342/382 [08:57<00:09,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No neighbors for fdba0667-faa73efd-da3746a5-2a72a1fa-f5b292b7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 382/382 [09:07<00:00,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated reports for 380 test images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Set n-gram size\n",
        "n = 3\n",
        "\n",
        "# Generate reports for test images\n",
        "generated_reports = {}\n",
        "\n",
        "print(f\"Generating reports with {n}-gram model...\")\n",
        "for pred_dicom in tqdm.tqdm(test_df.dicom_id.values):\n",
        "    # Skip if we don't have neighbors for this test image\n",
        "    if pred_dicom not in neighbors:\n",
        "        print(f\"Warning: No neighbors for {pred_dicom}\")\n",
        "        continue\n",
        "\n",
        "    # Build n-gram model from the neighbors' reports\n",
        "    nn = neighbors[pred_dicom]\n",
        "    LM = fit(nn, n=n)\n",
        "\n",
        "    # Skip if model is empty\n",
        "    if not LM:\n",
        "        print(f\"Warning: Empty language model for {pred_dicom}\")\n",
        "        continue\n",
        "\n",
        "    # Generate report by sampling from the n-gram model\n",
        "    generated_toks = [START for _ in range(n-1)]\n",
        "    current = generated_toks[-1]\n",
        "\n",
        "    # Generate until END token or max length\n",
        "    while current != END and len(generated_toks) < 100:\n",
        "        next_word = sample(LM, generated_toks, n)\n",
        "        generated_toks.append(next_word)\n",
        "        current = next_word\n",
        "\n",
        "    # Remove START tokens and potentially END token\n",
        "    generated_toks = generated_toks[n-1:]\n",
        "    if generated_toks[-1] == END:\n",
        "        generated_toks = generated_toks[:-1]\n",
        "\n",
        "    # Join tokens into text\n",
        "    generated_text = ' '.join(generated_toks)\n",
        "    generated_reports[pred_dicom] = generated_text\n",
        "\n",
        "print(f\"Generated reports for {len(generated_reports)} test images\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generated reports\n",
        "from time import gmtime, strftime\n",
        "\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "pred_dir = os.path.join(base_path, 'output')\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "# Save the generated reports\n",
        "pred_file = os.path.join(pred_dir, f'{n}-gram.tsv')\n",
        "print(f\"Saving predictions to {pred_file}\")\n",
        "\n",
        "with open(pred_file, 'w') as f:\n",
        "    print('dicom_id\\tgenerated', file=f)\n",
        "    for dicom_id, generated in sorted(generated_reports.items()):\n",
        "        # Clean up the text (remove any tabs)\n",
        "        cleaned_text = generated.replace('\\t', ' ')\n",
        "        print(f'{dicom_id}\\t{cleaned_text}', file=f)\n",
        "\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA3WR2nc5_5m",
        "outputId": "8d5b87fe-104e-4bde-91a1-f93aa9e138a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-10 04:14:33\n",
            "Saving predictions to /content/drive/MyDrive/mimic-cxr-project/output/3-gram.tsv\n",
            "2025-04-10 04:14:33\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}