{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "V5E1",
   "authorship_tag": "ABX9TyNvZf9716USGnhbm/gJ7mBN",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jasleenkaursandhu/Reproducing-chest-xray-report-generation-boag/blob/main/3gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sP0BluOO0DY1",
    "ExecuteTime": {
     "end_time": "2025-04-23T16:39:22.881892Z",
     "start_time": "2025-04-23T16:36:28.782563Z"
    }
   },
   "source": [
    "# N-gram Model for Report Generation\n",
    "# This notebook implements a conditional n-gram language model for chest X-ray report generation\n",
    "# based on the Boag et al. paper \"Baselines for Chest X-Ray Report Generation\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# Set up paths\n",
    "base_path = '/Users/simeon/Documents/DLH/content/mimic-cxr-project'\n",
    "!mkdir -p {base_path}/data\n",
    "!mkdir -p {base_path}/output\n",
    "\n",
    "# Import the report parser module\n",
    "import sys\n",
    "sys.path.append(f\"{base_path}/modules\")\n",
    "from report_parser import parse_report, MIMIC_RE\n",
    "print(\"Successfully imported report parser module\")\n",
    "\n",
    "# Load train and test data\n",
    "data_dir = os.path.join(base_path, 'data')\n",
    "files_path = os.path.join(base_path, 'new_files')\n",
    "output_dir = os.path.join(base_path, 'output')\n",
    "reports_dir = os.path.join(base_path, 'reports')\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.tsv'), sep='\\t')\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'test.tsv'), sep='\\t')\n",
    "\n",
    "print(f\"Train data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Load the top 100 neighbors for each test image\n",
    "neighbors_path = os.path.join(output_dir, 'top100_neighbors.pkl')\n",
    "\n",
    "if os.path.exists(neighbors_path):\n",
    "    with open(neighbors_path, 'rb') as f:\n",
    "        neighbors = pickle.load(f)\n",
    "\n",
    "    print(f\"Loaded neighbors for {len(neighbors)} test images\")\n",
    "    print(f\"Sample neighbors for first test image: {list(neighbors.items())[0][1][:5]}...\")\n",
    "else:\n",
    "    print(f\"Warning: Neighbors file not found at {neighbors_path}\")\n",
    "    print(\"Please run the feature extraction notebook first to generate the neighbors file.\")\n",
    "    neighbors = {}\n",
    "\n",
    "# Map each dicom to its study_id\n",
    "report_id_column = 'study_id'\n",
    "report_lookup = dict(train_df[['dicom_id', report_id_column]].values)\n",
    "print(f\"Created lookup dictionary for {len(report_lookup)} training images\")\n",
    "\n",
    "# Define the n-gram model\n",
    "class ConditionalNGramLM:\n",
    "    \"\"\"\n",
    "    Conditional n-gram language model as described in the paper.\n",
    "\n",
    "    For each test image, we build a language model based on\n",
    "    the reports of its closest 100 training images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n=3):\n",
    "        \"\"\"Initialize the n-gram model with specified n.\"\"\"\n",
    "        self.n = n\n",
    "        self.START = \"<s>\"\n",
    "        self.END = \"</s>\"\n",
    "\n",
    "    def build_lm(self, reports):\n",
    "        \"\"\"\n",
    "        Build an n-gram language model from a collection of reports.\n",
    "\n",
    "        Args:\n",
    "            reports (list): List of report texts\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary mapping n-gram contexts to next word distributions\n",
    "        \"\"\"\n",
    "        if not reports:\n",
    "            return {}\n",
    "\n",
    "        # Language model dictionary\n",
    "        lm = defaultdict(Counter)\n",
    "\n",
    "        for report in reports:\n",
    "            if not report or not isinstance(report, str):\n",
    "                continue\n",
    "\n",
    "            # Tokenize and preprocess\n",
    "            tokens = report.lower().split()\n",
    "\n",
    "            # Handle special case for unigram (1-gram) model\n",
    "            if self.n == 1:\n",
    "                # For 1-gram, we just need word frequencies (no context)\n",
    "                for token in tokens:\n",
    "                    lm[()][token] += 1\n",
    "                # Add END token with appropriate frequency\n",
    "                lm[()][self.END] += 1\n",
    "            else:\n",
    "                # Add START and END tokens\n",
    "                padded_tokens = [self.START] * (self.n - 1) + tokens + [self.END]\n",
    "\n",
    "                # Build n-grams\n",
    "                for i in range(len(padded_tokens) - self.n + 1):\n",
    "                    context = tuple(padded_tokens[i:i+self.n-1])\n",
    "                    next_word = padded_tokens[i+self.n-1]\n",
    "                    lm[context][next_word] += 1\n",
    "\n",
    "        return lm\n",
    "\n",
    "    def sample(self, lm):\n",
    "        \"\"\"\n",
    "        Generate text by sampling from the language model.\n",
    "\n",
    "        Args:\n",
    "            lm (dict): Language model\n",
    "\n",
    "        Returns:\n",
    "            str: Generated text\n",
    "        \"\"\"\n",
    "        if not lm:\n",
    "            return \"\"\n",
    "\n",
    "        # Handle special case for unigram model\n",
    "        if self.n == 1:\n",
    "            if () not in lm:\n",
    "                return \"\"\n",
    "\n",
    "            # Generate sequence for unigram model\n",
    "            generated = []\n",
    "            max_length = 100  # Prevent infinite loops\n",
    "\n",
    "            # Sample words based on their frequency until END or max_length\n",
    "            while len(generated) < max_length:\n",
    "                # Get all words and their counts\n",
    "                words, counts = zip(*lm[()].items())\n",
    "                total = sum(counts)\n",
    "                probs = [count/total for count in counts]\n",
    "\n",
    "                # Sample a word\n",
    "                current_word = np.random.choice(words, p=probs)\n",
    "\n",
    "                # Stop if END token is sampled\n",
    "                if current_word == self.END:\n",
    "                    break\n",
    "\n",
    "                generated.append(current_word)\n",
    "\n",
    "            return \" \".join(generated)\n",
    "\n",
    "        # Standard n-gram model (n â‰¥ 2)\n",
    "        # Start with START tokens\n",
    "        generated = [self.START] * (self.n - 1)\n",
    "        current_word = self.START\n",
    "\n",
    "        # Generate words until END token or max length reached\n",
    "        max_length = 100  # Prevent infinite loops\n",
    "        while current_word != self.END and len(generated) < max_length:\n",
    "            # Get the current context\n",
    "            context = tuple(generated[-(self.n-1):])\n",
    "\n",
    "            # If context not in language model, stop generation\n",
    "            if context not in lm or not lm[context]:\n",
    "                break\n",
    "\n",
    "            # Sample from the distribution of next words\n",
    "            next_words = lm[context]\n",
    "            words, counts = zip(*next_words.items())\n",
    "            total = sum(counts)\n",
    "            probs = [count/total for count in counts]\n",
    "\n",
    "            current_word = np.random.choice(words, p=probs)\n",
    "            generated.append(current_word)\n",
    "\n",
    "        # Remove START tokens and END token if present\n",
    "        result = generated[(self.n-1):] if self.n > 1 else generated\n",
    "        if result and result[-1] == self.END:\n",
    "            result = result[:-1]\n",
    "\n",
    "        return \" \".join(result)\n",
    "\n",
    "    def generate_report(self, neighbor_reports):\n",
    "        \"\"\"\n",
    "        Generate a report for a test image based on its neighbors' reports.\n",
    "\n",
    "        Args:\n",
    "            neighbor_reports (list): Reports from neighboring training images\n",
    "\n",
    "        Returns:\n",
    "            str: Generated report\n",
    "        \"\"\"\n",
    "        # Build language model from neighbor reports\n",
    "        lm = self.build_lm(neighbor_reports)\n",
    "\n",
    "        # Sample from the language model\n",
    "        return self.sample(lm)\n",
    "\n",
    "# Function to retrieve reports for a list of DICOM IDs\n",
    "def get_reports_for_dicoms(dicom_ids):\n",
    "    \"\"\"\n",
    "    Get the reports for a list of DICOM IDs.\n",
    "\n",
    "    Args:\n",
    "        dicom_ids (list): List of DICOM IDs\n",
    "\n",
    "    Returns:\n",
    "        list: List of report texts\n",
    "    \"\"\"\n",
    "    reports = []\n",
    "\n",
    "    for dicom_id in dicom_ids:\n",
    "        # Skip if no report lookup available\n",
    "        if dicom_id not in report_lookup:\n",
    "            continue\n",
    "\n",
    "        # Get report ID and subject ID\n",
    "        report_id = report_lookup[dicom_id]\n",
    "        subject_row = train_df[train_df.dicom_id == dicom_id]\n",
    "\n",
    "        if len(subject_row) == 0:\n",
    "            continue\n",
    "\n",
    "        subject_id = subject_row.iloc[0]['subject_id']\n",
    "\n",
    "        # Construct path to report\n",
    "        subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
    "        subject_dir = f\"p{subject_id}\"\n",
    "        study_dir = f\"s{report_id}\"\n",
    "        report_path = os.path.join(reports_dir, 'files', subject_prefix, subject_dir, f\"{study_dir}.txt\")\n",
    "\n",
    "        # Parse report\n",
    "        try:\n",
    "            if os.path.exists(report_path):\n",
    "                report = parse_report(report_path)\n",
    "\n",
    "                # Add findings section if available\n",
    "                if 'findings' in report:\n",
    "                    reports.append(report['findings'])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return reports\n",
    "\n",
    "# Generate reports using different n-gram sizes\n",
    "for n_value in [1, 2, 3]:  # The paper tested 1-gram, 2-gram, and 3-gram models\n",
    "    print(f\"\\nGenerating reports with {n_value}-gram model...\")\n",
    "\n",
    "    # Initialize n-gram model\n",
    "    ngram_model = ConditionalNGramLM(n=n_value)\n",
    "\n",
    "    # Generate reports for test images\n",
    "    generated_reports = {}\n",
    "\n",
    "    for pred_dicom in tqdm.tqdm(test_df.dicom_id.values):\n",
    "        # Skip if no neighbors\n",
    "        if pred_dicom not in neighbors:\n",
    "            print(f\"Warning: No neighbors for {pred_dicom}\")\n",
    "            continue\n",
    "\n",
    "        # Get closest 100 training images\n",
    "        nn_dicoms = neighbors[pred_dicom]\n",
    "\n",
    "        # Get reports for these neighbors\n",
    "        neighbor_reports = get_reports_for_dicoms(nn_dicoms)\n",
    "\n",
    "        # Skip if no reports found\n",
    "        if not neighbor_reports:\n",
    "            continue\n",
    "\n",
    "        # Generate report\n",
    "        generated_text = ngram_model.generate_report(neighbor_reports)\n",
    "        generated_reports[pred_dicom] = generated_text\n",
    "\n",
    "    print(f\"Generated reports for {len(generated_reports)}/{len(test_df)} test images\")\n",
    "\n",
    "    # Save the generated reports\n",
    "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "\n",
    "    pred_file = os.path.join(output_dir, f'{n_value}-gram.tsv')\n",
    "    print(f\"Saving predictions to {pred_file}\")\n",
    "\n",
    "    with open(pred_file, 'w') as f:\n",
    "        print('dicom_id\\tgenerated', file=f)\n",
    "        for dicom_id, generated in sorted(generated_reports.items()):\n",
    "            # Clean up the text (remove any tabs)\n",
    "            cleaned_text = generated.replace('\\t', ' ')\n",
    "            print(f'{dicom_id}\\t{cleaned_text}', file=f)\n",
    "\n",
    "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "\n",
    "    # Display sample reports\n",
    "    if n_value == 3:  # Only show samples for 3-gram model\n",
    "        print(\"\\nSample reports from 3-gram model:\")\n",
    "        sample_count = min(3, len(generated_reports))\n",
    "        sample_dicoms = list(generated_reports.keys())[:sample_count]\n",
    "\n",
    "        for dicom_id in sample_dicoms:\n",
    "            print(f\"\\nSample report for {dicom_id}:\")\n",
    "            report_text = generated_reports[dicom_id]\n",
    "\n",
    "            # Print preview of the report\n",
    "            if len(report_text) > 200:\n",
    "                print(report_text[:200] + \"...\")\n",
    "            else:\n",
    "                print(report_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported report parser module\n",
      "Train data shape: (4291, 3)\n",
      "Test data shape: (1757, 3)\n",
      "Loaded neighbors for 1757 test images\n",
      "Sample neighbors for first test image: ['ddb090f1-aa619dfb-67d4ca4a-110f9b6d-c6f8010a', 'd98be0d5-a648e485-4473a3ef-7762b3ef-2d70507e', '6786fea2-27b2011b-1cd0587c-3def265e-037893d7', '1eb85d94-6afece9c-be1737c8-52194ea1-208e72ab', 'dccd4d70-adbfd13a-c725043f-e14b2cf7-dcd6c0ad']...\n",
      "Created lookup dictionary for 4291 training images\n",
      "\n",
      "Generating reports with 1-gram model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1757/1757 [01:07<00:00, 26.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated reports for 1757/1757 test images\n",
      "2025-04-23 16:37:36\n",
      "Saving predictions to /Users/simeon/Documents/DLH/content/mimic-cxr-project/output/1-gram.tsv\n",
      "2025-04-23 16:37:36\n",
      "\n",
      "Generating reports with 2-gram model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1757/1757 [00:52<00:00, 33.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated reports for 1757/1757 test images\n",
      "2025-04-23 16:38:29\n",
      "Saving predictions to /Users/simeon/Documents/DLH/content/mimic-cxr-project/output/2-gram.tsv\n",
      "2025-04-23 16:38:29\n",
      "\n",
      "Generating reports with 3-gram model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1757/1757 [00:53<00:00, 32.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated reports for 1757/1757 test images\n",
      "2025-04-23 16:39:22\n",
      "Saving predictions to /Users/simeon/Documents/DLH/content/mimic-cxr-project/output/3-gram.tsv\n",
      "2025-04-23 16:39:22\n",
      "\n",
      "Sample reports from 3-gram model:\n",
      "\n",
      "Sample report for 20386a2d-1f7a8868-f12e22ac-0d625d27-4c38c8e2:\n",
      "the endotracheal tube terminates approximately 2 cm from the carina. enteric tube terminates approximately 2 cm from the carina. enteric tube terminates approximately 2 cm from the carina. enteric tub...\n",
      "\n",
      "Sample report for 63100eab-9e8a8d90-392bc822-325de482-69a64e3b:\n",
      "a left-sided chest tube. there is no consolidation or pneumothorax is clearly identified. no acute osseous abnormalities demonstrated.\n",
      "\n",
      "Sample report for 17269efa-b016a94d-1361e8df-ac428071-d1133672:\n",
      "compared to , there is no pneumothorax. no overt chf. no focal consolidation, pleural effusion or pneumothorax. the cardiomediastinal and hilar structures are intact.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ]
}
