{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNYugpQFcbG0XJIlWDlN2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasleenkaursandhu/Reproducing-chest-xray-report-generation-boag/blob/main/random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MCTKXpdNwTOJ"
      },
      "outputs": [],
      "source": [
        "# Random Baseline Model for Report Generation\n",
        "# This notebook implements a simple random baseline model for chest X-ray report generation.\n",
        "# The baseline randomly selects a report from the training set for each test image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "import gzip\n",
        "import random\n",
        "import re\n",
        "import warnings\n",
        "!pip install pydicom\n",
        "import pydicom\n",
        "from collections import Counter, defaultdict\n",
        "from time import gmtime, strftime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMOahgQTwhNG",
        "outputId": "0587a9a4-e48a-4a65-9e36-1248d7bac6a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/mimic-cxr-project'\n",
        "!mkdir -p {base_path}/data\n",
        "!mkdir -p {base_path}/output\n",
        "!mkdir -p {base_path}/features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54HbNZvfwpt2",
        "outputId": "371736ba-9e64-48cf-ea6e-251797240a3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the report parser module\n",
        "import sys\n",
        "sys.path.append(f\"{base_path}/modules\")\n",
        "from report_parser import parse_report, MIMIC_RE\n",
        "print(\"Successfully imported report parser module\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bzsvz3EwwK0",
        "outputId": "3816a495-dbe1-4274-b500-77a4b8d8a417"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported report parser module\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test data\n",
        "data_dir = os.path.join(base_path, 'data')\n",
        "files_path = os.path.join(base_path, 'files')\n",
        "output_dir = os.path.join(base_path, 'output')\n",
        "features_dir = os.path.join(base_path, 'features')\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(data_dir, 'train.tsv'), sep='\\t')\n",
        "test_df = pd.read_csv(os.path.join(data_dir, 'test.tsv'), sep='\\t')\n",
        "\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLN-bGUjw0Jl",
        "outputId": "54887bf7-a6fb-426f-fa52-ae52534aba7a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (824, 3)\n",
            "Test data shape: (382, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Implementing Random Baseline Model\")\n",
        "\n",
        "# Define the path to the files directory\n",
        "files_path = os.path.join(base_path, 'files')\n",
        "\n",
        "# Map each dicom to its corresponding report identifier\n",
        "report_id_column = 'study_id'\n",
        "if report_id_column in train_df.columns:\n",
        "    report_lookup = dict(train_df[['dicom_id', report_id_column]].values)\n",
        "    print(f\"Created lookup using {report_id_column}\")\n",
        "else:\n",
        "    print(f\"Warning: {report_id_column} not found in columns: {train_df.columns.tolist()}\")\n",
        "    report_lookup = {}\n",
        "\n",
        "print(\"Sample of lookup dictionary:\")\n",
        "print(dict(list(report_lookup.items())[:5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1J0eOFnxC0E",
        "outputId": "7d436dbc-9a40-4568-b305-422edb543bf5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementing Random Baseline Model\n",
            "Created lookup using study_id\n",
            "Sample of lookup dictionary:\n",
            "{'dfd9a06c-2994892e-f4a6bc1c-f6ec4803-283e5005': 55606773, 'ab50de59-ebf1d4df-20709b76-e8df1c5b-02561a38': 55244750, 'fafaee95-e11d24c5-ad39cfcd-302ac853-4a6f16ac': 58401243, 'fd53f5b0-0070f205-6c47cbe6-eaf7140d-12b09066': 57100718, '78e28f8c-fc928714-2cdc13f2-e6e45d40-89cb7eca': 53346921}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random reports for each test image\n",
        "generated_reports = {}\n",
        "\n",
        "for pred_dicom in tqdm.tqdm(test_df.dicom_id.values):\n",
        "    found = False\n",
        "    attempts = 0\n",
        "    max_attempts = 100  # Limit attempts to avoid infinite loops\n",
        "\n",
        "    while not found and attempts < max_attempts:\n",
        "        attempts += 1\n",
        "\n",
        "        # Randomly select a training image\n",
        "        nearest_dicom = random.choice(train_df.dicom_id.values)\n",
        "\n",
        "        if nearest_dicom not in report_lookup:\n",
        "            continue\n",
        "\n",
        "        report_id = report_lookup[nearest_dicom]\n",
        "\n",
        "        # Get corresponding subject_id\n",
        "        subject_row = train_df[train_df.dicom_id == nearest_dicom]\n",
        "        if len(subject_row) == 0:\n",
        "            continue\n",
        "\n",
        "        subject_id = subject_row.iloc[0]['subject_id']\n",
        "\n",
        "        # Construct path to the report\n",
        "        subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
        "        subject_dir = f\"p{subject_id}\"\n",
        "        study_dir = f\"s{report_id}\"\n",
        "        report_file = f\"{study_dir}.txt\"\n",
        "        report_path = os.path.join(files_path, subject_prefix, subject_dir, report_file)\n",
        "\n",
        "        # Parse the report to extract sections\n",
        "        try:\n",
        "            if os.path.exists(report_path):\n",
        "                report = parse_report(report_path)\n",
        "\n",
        "                # If the report has a findings section, use it\n",
        "                if 'findings' in report:\n",
        "                    found = True\n",
        "                    generated_reports[pred_dicom] = report['findings']\n",
        "        except Exception as e:\n",
        "            # Skip this report and try another\n",
        "            continue\n",
        "\n",
        "    if not found:\n",
        "        print(f\"Warning: Could not find a valid report for {pred_dicom} after {max_attempts} attempts\")\n",
        "\n",
        "print(f\"Generated random reports for {len(generated_reports)}/{len(test_df)} test images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZbSxfWexV9v",
        "outputId": "948dd88c-5f73-47b9-8f0e-bea4e7ee0519"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 382/382 [06:08<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated random reports for 382/382 test images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generated reports to a TSV file\n",
        "pred_dir = os.path.join(base_path, 'output')\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "pred_file = os.path.join(pred_dir, 'random.tsv')\n",
        "print(f\"Saving predictions to {pred_file}\")\n",
        "\n",
        "with open(pred_file, 'w') as f:\n",
        "    print('dicom_id\\tgenerated', file=f)\n",
        "    for dicom_id, generated in sorted(generated_reports.items()):\n",
        "        # Escape any tab characters in the generated text\n",
        "        cleaned_text = generated.replace('\\t', ' ')\n",
        "        print(f'{dicom_id}\\t{cleaned_text}', file=f)\n",
        "\n",
        "print(f\"Saved random baseline predictions to {pred_file}\")\n",
        "print(f\"Current time: {strftime('%Y-%m-%d %H:%M:%S', gmtime())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6qOl8uyxbem",
        "outputId": "80979da2-6a82-4cd5-e0f8-3617d39b73b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving predictions to /content/drive/MyDrive/mimic-cxr-project/output/random.tsv\n",
            "Saved random baseline predictions to /content/drive/MyDrive/mimic-cxr-project/output/random.tsv\n",
            "Current time: 2025-04-13 20:17:42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample of generated reports\n",
        "sample_count = min(3, len(generated_reports))\n",
        "sample_dicoms = list(generated_reports.keys())[:sample_count]\n",
        "\n",
        "for dicom_id in sample_dicoms:\n",
        "    print(f\"\\nSample report for {dicom_id}:\")\n",
        "    report_text = generated_reports[dicom_id]\n",
        "\n",
        "    # Print preview of the report (first 200 characters)\n",
        "    if len(report_text) > 200:\n",
        "        print(report_text[:200] + \"...\")\n",
        "    else:\n",
        "        print(report_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4h7wo_ixeUU",
        "outputId": "ccbf7ade-7559-4873-816e-49ae824258d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample report for fea90b5d-a059ecc8-b5e68f8d-b7f33ed9-1d32d429:\n",
            "aside from minimal bibasilar atelectasis, the lungs are clear. the hilar and cardiomediastinal contours are normal. there is no pneumothorax. there is no pleural effusion. pulmonary vascularity is nor...\n",
            "\n",
            "Sample report for 06ba097a-bf8b917c-851d0e95-886936a1-90964781:\n",
            "heart size is normal. the mediastinal and hilar contours are normal. the pulmonary vasculature is normal. bibasilar atelectasis, although minimal, appears somewhat increased compared to the previous s...\n",
            "\n",
            "Sample report for 648449fa-5e173b2a-87663d57-4a0fbfc0-138e42c7:\n",
            "lung volumes are somewhat low in the patient is rotated to the left. bronchovascular markings remain prominent. there is no focal consolidation. the heart and mediastinal structures are stable, allowi...\n"
          ]
        }
      ]
    }
  ]
}