{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyPaIBsgrBSZvl9W/Jc4Mpin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasleenkaursandhu/Reproducing-chest-xray-report-generation-boag/blob/main/2gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sP0BluOO0DY1"
      },
      "outputs": [],
      "source": [
        "# N-gram Model for Report Generation\n",
        "# This notebook implements an n-gram language model for chest X-ray report generation.\n",
        "# The model selects the most similar training images for each test image and builds a language model from their reports.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# docker image code to made files labelled for chexpert\n",
        "# For 1-gram\n",
        "##docker run --platform linux/amd64 -v /Users/jasleensandhu/Desktop/CS598DLH:/data uwizeye2/chexpert-labeler:amd64 python label.py --reports_path /data/1gram_headerless.csv --output_path /data/output/labeled_1gram.csv --verbose\n",
        "\n",
        "# For 2-gram\n",
        "##docker run --platform linux/amd64 -v /Users/jasleensandhu/Desktop/CS598DLH:/data uwizeye2/chexpert-labeler:amd64 python label.py --reports_path /data/2gram_headerless.csv --output_path /data/output/labeled_2gram.csv --verbose\n",
        "\n",
        "# For 3-gram\n",
        "##docker run --platform linux/amd64 -v /Users/jasleensandhu/Desktop/CS598DLH:/data uwizeye2/chexpert-labeler:amd64 python label.py --reports_path /data/3gram_headerless.csv --output_path /data/output/labeled_3gram.csv --verbose"
      ],
      "metadata": {
        "id": "YQLrbvAkNmNi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "from collections import defaultdict, Counter\n",
        "import pickle\n",
        "import gzip\n",
        "import random\n",
        "import re\n",
        "import warnings\n",
        "!pip install pydicom\n",
        "import pydicom\n",
        "from time import gmtime, strftime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOX8yrJv0LFn",
        "outputId": "89792a23-03fd-4eaa-b75a-9ffd40b19d1c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/mimic-cxr-project'\n",
        "!mkdir -p {base_path}/data\n",
        "!mkdir -p {base_path}/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WANs5gfU0Rki",
        "outputId": "88ad7a6b-048d-4a6a-d829-4fcbffb9e3d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the report parser module\n",
        "import sys\n",
        "sys.path.append(f\"{base_path}/modules\")\n",
        "from report_parser import parse_report, MIMIC_RE\n",
        "print(\"Successfully imported report parser module\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Mq-yU00XtS",
        "outputId": "da5b5f9d-9b23-410e-81f8-7e11717a11ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported report parser module\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test data\n",
        "data_dir = os.path.join(base_path, 'data')\n",
        "files_path = os.path.join(base_path, 'files')\n",
        "output_dir = os.path.join(base_path, 'output')\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(data_dir, 'train.tsv'), sep='\\t')\n",
        "test_df = pd.read_csv(os.path.join(data_dir, 'test.tsv'), sep='\\t')\n",
        "\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZKWVShS0bVI",
        "outputId": "4ced1634-15be-4833-fb40-6508beb1cbc9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (2243, 3)\n",
            "Test data shape: (871, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the top 100 neighbors for each test image\n",
        "neighbors_path = os.path.join(output_dir, 'top100_neighbors.pkl')\n",
        "\n",
        "if os.path.exists(neighbors_path):\n",
        "    with open(neighbors_path, 'rb') as f:\n",
        "        neighbors = pickle.load(f)\n",
        "\n",
        "    print(f\"Loaded neighbors for {len(neighbors)} test images\")\n",
        "    print(f\"Sample neighbors for first test image: {list(neighbors.items())[0][1][:5]}...\")\n",
        "else:\n",
        "    print(f\"Warning: Neighbors file not found at {neighbors_path}\")\n",
        "    print(\"Please run the KNN model first to generate the neighbors file.\")\n",
        "    neighbors = {}\n",
        "    for dicom_id in test_df.dicom_id.values:\n",
        "        neighbors[dicom_id] = random.sample(train_df.dicom_id.tolist(), min(100, len(train_df)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wplhnyXG0fja",
        "outputId": "bf7893da-b862-43b7-a897-0a226d212aa4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded neighbors for 868 test images\n",
            "Sample neighbors for first test image: ['9368d351-90051a0c-c8dc80c0-96a2254d-2a884177', '6cad5cfd-bf8d1805-f3a3906a-588e0bfe-fe5c153d', 'd6c4c0d6-f12c2415-a5b3d2df-bcc4a202-442d3523', 'd18b8527-4c5a26fd-ac1041dd-8f9fd75f-4327f46f', '6083cad9-c1727fa2-b948d959-763ca27c-6391e63b']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map each dicom to its study_id\n",
        "report_id_column = 'study_id'\n",
        "report_lookup = dict(train_df[['dicom_id', report_id_column]].values)\n",
        "print(f\"Created lookup dictionary for {len(report_lookup)} training images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82hk_03j0poo",
        "outputId": "c7a95932-5dbf-435e-8f8f-29a3bcf00230"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created lookup dictionary for 2243 training images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokens for sequence boundaries\n",
        "START = '<START>'\n",
        "END = '<END>'\n",
        "\n",
        "# Build n-gram language model from neighbors\n",
        "def fit(dicom_ids, n=3):\n",
        "    \"\"\"Build language model from the reports of the given dicom_ids\"\"\"\n",
        "    # Language model maps context (n-1 previous words) to possible next words\n",
        "    LM = defaultdict(Counter)\n",
        "\n",
        "    for dicom_id in dicom_ids:\n",
        "        if dicom_id not in report_lookup:\n",
        "            continue\n",
        "\n",
        "        report_id = report_lookup[dicom_id]\n",
        "\n",
        "        # Get corresponding subject_id\n",
        "        subject_row = train_df[train_df.dicom_id == dicom_id]\n",
        "        if len(subject_row) == 0:\n",
        "            continue\n",
        "\n",
        "        subject_id = subject_row.iloc[0]['subject_id']\n",
        "\n",
        "        # Construct path to the report\n",
        "        subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
        "        subject_dir = f\"p{subject_id}\"\n",
        "        study_dir = f\"s{report_id}\"\n",
        "        report_file = f\"{study_dir}.txt\"\n",
        "        report_path = os.path.join(files_path, subject_prefix, subject_dir, report_file)\n",
        "\n",
        "        # Parse the report\n",
        "        try:\n",
        "            if os.path.exists(report_path):\n",
        "                parsed_report = parse_report(report_path)\n",
        "\n",
        "                if 'findings' in parsed_report:\n",
        "                    # Tokenize the findings text\n",
        "                    toks = parsed_report['findings'].replace('.', ' . ').split()\n",
        "\n",
        "                    # Add padding tokens at the beginning and END token at the end\n",
        "                    padded_toks = [START for _ in range(n-1)] + toks + [END]\n",
        "\n",
        "                    # Build n-gram model by counting follow words for each context\n",
        "                    for i in range(len(padded_toks) - n + 1):\n",
        "                        context = tuple(padded_toks[i:i+n-1])\n",
        "                        target = padded_toks[i+n-1]\n",
        "                        sim = 1\n",
        "                        LM[context][target] += sim\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    return LM"
      ],
      "metadata": {
        "id": "z9qIMiLI0wq_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample from the n-gram model\n",
        "def sample(LM, seq_so_far, n):\n",
        "    \"\"\"Sample the next word based on the n-gram language model\"\"\"\n",
        "    last = tuple(seq_so_far[-(n-1):])\n",
        "\n",
        "    if last not in LM or not LM[last]:\n",
        "        # If context not found in model, return END token\n",
        "        return END\n",
        "\n",
        "    words, counts = zip(*LM[last].items())\n",
        "    total = sum(counts)\n",
        "    P = np.array(counts) / total\n",
        "\n",
        "    # Sample next word based on probabilities\n",
        "    choice = np.random.choice(words, p=P)\n",
        "    return choice"
      ],
      "metadata": {
        "id": "f_f30cQv01P3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set n-gram size\n",
        "n = 2\n",
        "\n",
        "# Generate reports for test images\n",
        "generated_reports = {}\n",
        "\n",
        "print(f\"Generating reports with {n}-gram model...\")\n",
        "for pred_dicom in tqdm.tqdm(test_df.dicom_id.values):\n",
        "    # Skip if we don't have neighbors for this test image\n",
        "    if pred_dicom not in neighbors:\n",
        "        print(f\"Warning: No neighbors for {pred_dicom}\")\n",
        "        continue\n",
        "\n",
        "    # Build n-gram model from the neighbors' reports\n",
        "    nn = neighbors[pred_dicom]\n",
        "    LM = fit(nn, n=n)\n",
        "\n",
        "    # Skip if model is empty\n",
        "    if not LM:\n",
        "        print(f\"Warning: Empty language model for {pred_dicom}\")\n",
        "        continue\n",
        "\n",
        "    # Handle initialization differently for different n values\n",
        "    if n == 1:\n",
        "        # For 1-gram, we don't need context\n",
        "        generated_toks = []\n",
        "        current = START  # Start token won't actually be used for context\n",
        "    else:\n",
        "        # For n > 1, initialize with n-1 START tokens\n",
        "        generated_toks = [START for _ in range(n-1)]\n",
        "        current = generated_toks[-1]\n",
        "\n",
        "    # Generate until END token or max length\n",
        "    while current != END and len(generated_toks) < 100:\n",
        "        next_word = sample(LM, generated_toks, n)\n",
        "        generated_toks.append(next_word)\n",
        "        current = next_word\n",
        "\n",
        "    # Remove START tokens (if any) and potentially END token\n",
        "    if n > 1:\n",
        "        generated_toks = generated_toks[n-1:]\n",
        "    if generated_toks and generated_toks[-1] == END:\n",
        "        generated_toks = generated_toks[:-1]\n",
        "\n",
        "    # Join tokens into text\n",
        "    generated_text = ' '.join(generated_toks)\n",
        "    generated_reports[pred_dicom] = generated_text\n",
        "\n",
        "print(f\"Generated reports for {len(generated_reports)} test images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXx2HKrD055T",
        "outputId": "0985e658-2a84-44be-e369-7a34843e0964"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating reports with 2-gram model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 66/871 [00:17<03:46,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No neighbors for fdba0667-faa73efd-da3746a5-2a72a1fa-f5b292b7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 140/871 [00:36<03:05,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No neighbors for a235b65b-e777f854-a98de6d6-2f3d33d8-bca255ec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 142/871 [00:37<02:46,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No neighbors for 4e5eebbe-0eddc029-b15d4941-d49ec4dd-f18951c0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 871/871 [03:55<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated reports for 868 test images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generated reports\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "pred_dir = os.path.join(base_path, 'output')\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "# Save the generated reports\n",
        "pred_file = os.path.join(pred_dir, f'{n}-gram.tsv')\n",
        "print(f\"Saving predictions to {pred_file}\")\n",
        "\n",
        "with open(pred_file, 'w') as f:\n",
        "    print('dicom_id\\tgenerated', file=f)\n",
        "    for dicom_id, generated in sorted(generated_reports.items()):\n",
        "        # Clean up the text (remove any tabs)\n",
        "        cleaned_text = generated.replace('\\t', ' ')\n",
        "        print(f'{dicom_id}\\t{cleaned_text}', file=f)\n",
        "\n",
        "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7acpffo09p2",
        "outputId": "5ff9d526-e60d-4028-bd45-7aa727d65425"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-17 19:40:59\n",
            "Saving predictions to /content/drive/MyDrive/mimic-cxr-project/output/2-gram.tsv\n",
            "2025-04-17 19:40:59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample of generated reports\n",
        "sample_count = min(3, len(generated_reports))\n",
        "sample_dicoms = list(generated_reports.keys())[:sample_count]\n",
        "\n",
        "for dicom_id in sample_dicoms:\n",
        "    print(f\"\\nSample report for {dicom_id}:\")\n",
        "    report_text = generated_reports[dicom_id]\n",
        "\n",
        "    # Print preview of the report (first 200 characters)\n",
        "    if len(report_text) > 200:\n",
        "        print(report_text[:200] + \"...\")\n",
        "    else:\n",
        "        print(report_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhBR88bj1Ai3",
        "outputId": "f00b8845-6980-47bd-abad-1d02e0f2d847"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample report for 6b31c47c-641e9905-9713bf8c-5d916738-736686e1:\n",
            "compared to be present . no pneumothorax . the right upper quadrant of pneumothorax .\n",
            "\n",
            "Sample report for ea38e7bb-cba206f9-4189840d-16b60305-bf6c4b9a:\n",
            "heart size . there is top normal .\n",
            "\n",
            "Sample report for 0ff89f65-95a04de8-2fe6671c-5fcd970e-32c68b41:\n",
            "lung volumes .\n"
          ]
        }
      ]
    }
  ]
}