{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T20:40:51.448272Z",
     "start_time": "2025-04-18T01:17:45.798458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CNN-RNN Model with Beam Search for Chest X-Ray Report Generation\n",
    "# Modified to fix repetition issues and improve generation quality\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "import tqdm\n",
    "import pydicom\n",
    "import string\n",
    "import certifi\n",
    "import ssl\n",
    "import heapq\n",
    "import math\n",
    "\n",
    "# Fix SSL certificate issues in macOS\n",
    "import os\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = certifi.where()\n",
    "\n",
    "# Simple tokenizer to avoid NLTK dependency\n",
    "def simple_tokenize(text):\n",
    "    \"\"\"Simple tokenizer that splits text on whitespace and punctuation.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    # Remove punctuation and replace with space\n",
    "    for char in string.punctuation:\n",
    "        text = text.replace(char, ' ' + char + ' ')\n",
    "\n",
    "    # Split on whitespace and filter empty tokens\n",
    "    tokens = [token for token in text.lower().split() if token.strip()]\n",
    "    return tokens\n",
    "\n",
    "# Define paths (keep these the same)\n",
    "base_path = '/Users/simeon/Documents/DLH/content/mimic-cxr-project'\n",
    "data_dir = os.path.join(base_path, 'data')\n",
    "files_path = os.path.join(base_path, 'new_files')\n",
    "output_dir = os.path.join(base_path, 'output')\n",
    "reports_dir = os.path.join(base_path, 'reports')\n",
    "models_dir = os.path.join(base_path, 'models')\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Import the report parser module\n",
    "import sys\n",
    "sys.path.append(f\"{base_path}/modules\")\n",
    "from report_parser import parse_report, MIMIC_RE\n",
    "print(\"Successfully imported report parser module\")\n",
    "\n",
    "# Load train and test data\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.tsv'), sep='\\t')\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'test.tsv'), sep='\\t')\n",
    "\n",
    "print(f\"Train data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Enhanced Vocabulary class with frequency logging\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold=2):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"< SOS >\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"< SOS >\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.frequencies = {}  # Track word frequencies\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        self.frequencies = {}\n",
    "        idx = 4\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            # Use simple tokenizer\n",
    "            for word in simple_tokenize(sentence):\n",
    "                if word not in self.frequencies:\n",
    "                    self.frequencies[word] = 0\n",
    "                self.frequencies[word] += 1\n",
    "\n",
    "                if word not in self.stoi and self.frequencies[word] >= self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "\n",
    "        # Print top 20 most frequent words for debugging\n",
    "        print(\"Top 20 most frequent words:\")\n",
    "        for word, freq in sorted(self.frequencies.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "            print(f\"{word}: {freq}\")\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        # Use simple tokenizer\n",
    "        tokenized_text = simple_tokenize(text)\n",
    "\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
    "            for token in tokenized_text\n",
    "        ]\n",
    "\n",
    "# Class to load and preprocess the data\n",
    "class ChestXRayReportDataset(Dataset):\n",
    "    def __init__(self, df, is_train=True, transform=None, max_seq_length=100):\n",
    "        self.df = df\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.reports = []\n",
    "\n",
    "        # Extract reports if training\n",
    "        if self.is_train:\n",
    "            print(\"Extracting report texts for training data...\")\n",
    "            for _, row in tqdm.tqdm(self.df.iterrows(), total=len(self.df)):\n",
    "                subject_id = row['subject_id']\n",
    "                study_id = row['study_id']\n",
    "\n",
    "                # Construct path to report (FIXED PATH)\n",
    "                subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
    "                subject_dir = f\"p{subject_id}\"\n",
    "                study_dir = f\"s{study_id}\"\n",
    "\n",
    "                # Try different path structures\n",
    "                report_paths = [\n",
    "                    os.path.join(reports_dir, subject_prefix, subject_dir, f\"{study_dir}.txt\"),  # Original\n",
    "                    os.path.join(reports_dir, 'new_files', subject_prefix, subject_dir, f\"{study_dir}.txt\"),  # With 'new_files'\n",
    "                    os.path.join(reports_dir, 'files', subject_prefix, subject_dir, f\"{study_dir}.txt\"),  # With 'files'\n",
    "                    os.path.join(reports_dir, subject_prefix, subject_dir, study_dir, \"report.txt\")  # Alternative structure\n",
    "                ]\n",
    "\n",
    "                for report_path in report_paths:\n",
    "                    try:\n",
    "                        if os.path.exists(report_path):\n",
    "                            report = parse_report(report_path)\n",
    "                            if 'findings' in report and report['findings']:\n",
    "                                self.reports.append((row['dicom_id'], report['findings']))\n",
    "                                break  # Found a valid report, move to next row\n",
    "                    except Exception as e:\n",
    "                        continue  # Try next path\n",
    "\n",
    "            print(f\"Extracted {len(self.reports)} reports from training data\")\n",
    "\n",
    "            # If still no reports, add some dummy data for testing\n",
    "            if len(self.reports) == 0:\n",
    "                print(\"WARNING: No reports found! Adding dummy data for testing...\")\n",
    "                # Create a few dummy reports to allow model testing\n",
    "                for i in range(min(10, len(self.df))):\n",
    "                    self.reports.append((self.df.iloc[i]['dicom_id'], \"This is a dummy report for testing purposes.\"))\n",
    "\n",
    "        # Build DICOM paths\n",
    "        self.dicom_paths = []\n",
    "        for _, row in self.df.iterrows():\n",
    "            subject_id = row['subject_id']\n",
    "            study_id = row['study_id']\n",
    "            dicom_id = row['dicom_id']\n",
    "\n",
    "            # Construct path to DICOM file\n",
    "            subject_prefix = f\"p{str(subject_id)[:2]}\"\n",
    "            subject_dir = f\"p{subject_id}\"\n",
    "            study_dir = f\"s{study_id}\"\n",
    "            dicom_file = f\"{dicom_id}.dcm\"\n",
    "            dicom_path = os.path.join(files_path, subject_prefix, subject_dir, study_dir, dicom_file)\n",
    "\n",
    "            if os.path.exists(dicom_path):\n",
    "                self.dicom_paths.append((dicom_id, dicom_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dicom_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dicom_id, dicom_path = self.dicom_paths[idx]\n",
    "\n",
    "        # Load and transform image\n",
    "        try:\n",
    "            ds = pydicom.dcmread(dicom_path)\n",
    "            pixel_array = ds.pixel_array\n",
    "\n",
    "            # Normalize and convert to RGB\n",
    "            pixel_array = pixel_array / np.max(pixel_array)\n",
    "            img = np.uint8(pixel_array * 255)\n",
    "\n",
    "            # Convert to RGB\n",
    "            if len(img.shape) == 2:\n",
    "                img_rgb = np.stack([img, img, img], axis=2)\n",
    "            elif img.shape[2] == 1:\n",
    "                img_rgb = np.concatenate([img, img, img], axis=2)\n",
    "            else:\n",
    "                img_rgb = img\n",
    "\n",
    "            pil_img = Image.fromarray(img_rgb)\n",
    "            if self.transform:\n",
    "                image = self.transform(pil_img)\n",
    "        except Exception as e:\n",
    "            # Create blank image if loading fails\n",
    "            image = torch.zeros(3, 224, 224)\n",
    "\n",
    "        # Return image and report for training, only image for testing\n",
    "        if self.is_train:\n",
    "            report_text = \"\"\n",
    "            for report_id, report in self.reports:\n",
    "                if report_id == dicom_id:\n",
    "                    report_text = report\n",
    "                    break\n",
    "            return image, report_text, dicom_id\n",
    "        else:\n",
    "            return image, dicom_id\n",
    "\n",
    "    # Added method to get all reports for vocabulary building\n",
    "    def get_all_reports(self):\n",
    "        return [report for _, report in self.reports]\n",
    "\n",
    "# Improved CNN-RNN model with attention and beam search\n",
    "class CNNRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, cnn_feature_size):\n",
    "        super(CNNRNNModel, self).__init__()\n",
    "\n",
    "        # CNN encoder (DenseNet121)\n",
    "        print(\"Loading DenseNet121 model with pretrained weights...\")\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        self.densenet.classifier = nn.Linear(cnn_feature_size, embed_size)\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        # Initial projection for CNN features\n",
    "        self.feature_projection = nn.Linear(embed_size, hidden_size)\n",
    "\n",
    "        # LSTM decoder\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Store dimensions\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, images, captions=None, teacher_forcing_ratio=0.5):\n",
    "        # Extract features from images using CNN encoder\n",
    "        # [batch_size, 3, 224, 224] -> [batch_size, embed_size]\n",
    "        features = self.densenet(images)\n",
    "\n",
    "        # Project features to hidden state size\n",
    "        projected_features = self.feature_projection(features)\n",
    "\n",
    "        # Training mode with captions\n",
    "        if captions is not None:\n",
    "            batch_size = features.size(0)\n",
    "            caption_length = captions.size(1)\n",
    "\n",
    "            # Initialize tensor for storing outputs\n",
    "            outputs = torch.zeros(batch_size, caption_length, self.vocab_size).to(device)\n",
    "\n",
    "            # Initialize hidden and cell state with projected image features\n",
    "            h = projected_features.unsqueeze(0)  # [1, batch_size, hidden_size]\n",
    "            c = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "            # First input to LSTM is the SOS token\n",
    "            x = self.embedding(torch.ones(batch_size, 1, dtype=torch.long).to(device))  # [batch_size, 1, embed_size]\n",
    "\n",
    "            # Generate caption one word at a time\n",
    "            for t in range(caption_length):\n",
    "                # Forward through LSTM\n",
    "                lstm_out, (h, c) = self.lstm(x, (h, c))  # lstm_out: [batch_size, 1, hidden_size]\n",
    "\n",
    "                # Apply simple attention (we'll skip complex attention for now to avoid dimension issues)\n",
    "                # Forward through fully connected layer\n",
    "                out = self.fc(lstm_out)  # [batch_size, 1, vocab_size]\n",
    "\n",
    "                # Store output\n",
    "                outputs[:, t] = out.squeeze(1)  # [batch_size, vocab_size]\n",
    "\n",
    "                # Teacher forcing\n",
    "                use_teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "\n",
    "                if use_teacher_force and t < caption_length - 1:\n",
    "                    # Use ground truth as next input\n",
    "                    x = self.embedding(captions[:, t+1].unsqueeze(1))  # [batch_size, 1, embed_size]\n",
    "                else:\n",
    "                    # Use predicted word as next input\n",
    "                    pred_token = out.argmax(2)  # [batch_size, 1]\n",
    "                    x = self.embedding(pred_token)  # [batch_size, 1, embed_size]\n",
    "\n",
    "            return outputs\n",
    "\n",
    "        # Inference mode (using beam search)\n",
    "        else:\n",
    "            return self.beam_search(images, beam_size=3, max_length=100)\n",
    "\n",
    "    def beam_search(self, images, beam_size=3, max_length=100, temperature=1.0, repetition_penalty=1.2):\n",
    "        \"\"\"\n",
    "        Beam search implementation for better text generation\n",
    "        with repetition penalty to avoid word repetition\n",
    "        \"\"\"\n",
    "        batch_size = images.size(0)\n",
    "        results = []\n",
    "\n",
    "        for idx in range(batch_size):\n",
    "            # Extract features for a single image\n",
    "            image_features = self.densenet(images[idx:idx+1])  # [1, embed_size]\n",
    "\n",
    "            # Project features to hidden state size\n",
    "            projected_features = self.feature_projection(image_features)  # [1, hidden_size]\n",
    "\n",
    "            # Initialize hidden and cell states\n",
    "            h = projected_features.unsqueeze(0)  # [1, 1, hidden_size]\n",
    "            c = torch.zeros(1, 1, self.hidden_size).to(device)  # [1, 1, hidden_size]\n",
    "\n",
    "            # Start with SOS token\n",
    "            start_token = torch.ones(1, 1, dtype=torch.long).to(device)  # [1, 1]\n",
    "            start_embedding = self.embedding(start_token)  # [1, 1, embed_size]\n",
    "\n",
    "            # First forward pass to get initial predictions\n",
    "            lstm_out, (h, c) = self.lstm(start_embedding, (h, c))  # lstm_out: [1, 1, hidden_size]\n",
    "\n",
    "            # Get initial logits\n",
    "            logits = self.fc(lstm_out)  # [1, 1, vocab_size]\n",
    "            logits = logits.squeeze(0).squeeze(0)  # [vocab_size]\n",
    "\n",
    "            # Apply temperature sampling\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # [vocab_size]\n",
    "\n",
    "            # Get top-k candidates\n",
    "            topk_probs, topk_indices = torch.topk(probs, beam_size)  # [beam_size]\n",
    "\n",
    "            # Initialize beams\n",
    "            beams = [(math.log(prob.item()), [index.item()], h, c, {index.item(): 1})\n",
    "                     for prob, index in zip(topk_probs, topk_indices)]\n",
    "\n",
    "            # Beam search\n",
    "            for _ in range(max_length - 1):\n",
    "                new_beams = []\n",
    "\n",
    "                # Expand each beam\n",
    "                for log_prob, seq, hidden, cell, word_counts in beams:\n",
    "                    # Check if sequence ended\n",
    "                    if seq[-1] == 2:  # <EOS> token\n",
    "                        new_beams.append((log_prob, seq, hidden, cell, word_counts))\n",
    "                        continue\n",
    "\n",
    "                    # Prepare input for next step (last token)\n",
    "                    token = torch.tensor([[seq[-1]]], dtype=torch.long).to(device)\n",
    "                    token_embedding = self.embedding(token)  # [1, 1, embed_size]\n",
    "\n",
    "                    # Forward pass\n",
    "                    lstm_out, (new_hidden, new_cell) = self.lstm(token_embedding, (hidden, cell))\n",
    "\n",
    "                    # No attention for simplicity\n",
    "\n",
    "                    # Get logits\n",
    "                    logits = self.fc(lstm_out).squeeze(0).squeeze(0)  # [vocab_size]\n",
    "\n",
    "                    # Apply repetition penalty\n",
    "                    for word_idx, count in word_counts.items():\n",
    "                        logits[word_idx] /= repetition_penalty * count\n",
    "\n",
    "                    # Apply temperature\n",
    "                    logits = logits / temperature\n",
    "\n",
    "                    # Apply softmax\n",
    "                    probs = F.softmax(logits, dim=-1)  # [vocab_size]\n",
    "\n",
    "                    # Get top-k candidates for this beam\n",
    "                    topk_probs, topk_indices = torch.topk(probs, beam_size)  # [beam_size]\n",
    "\n",
    "                    # Add to new beams\n",
    "                    for prob, index in zip(topk_probs, topk_indices):\n",
    "                        # Create new sequence\n",
    "                        new_seq = seq + [index.item()]\n",
    "\n",
    "                        # Update word counts for repetition penalty\n",
    "                        new_word_counts = word_counts.copy()\n",
    "                        if index.item() in new_word_counts:\n",
    "                            new_word_counts[index.item()] += 1\n",
    "                        else:\n",
    "                            new_word_counts[index.item()] = 1\n",
    "\n",
    "                        # Calculate new log probability\n",
    "                        new_log_prob = log_prob + math.log(prob.item())\n",
    "\n",
    "                        # Add beam\n",
    "                        new_beams.append((new_log_prob, new_seq, new_hidden, new_cell, new_word_counts))\n",
    "\n",
    "                # Keep top beams\n",
    "                beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "\n",
    "                # Check if all beams end with <EOS>\n",
    "                if all(seq[-1] == 2 for _, seq, _, _, _ in beams):\n",
    "                    break\n",
    "\n",
    "            # Get best beam\n",
    "            best_beam = max(beams, key=lambda x: x[0])\n",
    "            best_seq = best_beam[1]\n",
    "\n",
    "            # Remove < SOS > and <EOS> tokens if present\n",
    "            if best_seq[0] == 1:  # < SOS >\n",
    "                best_seq = best_seq[1:]\n",
    "            if best_seq[-1] == 2:  # <EOS>\n",
    "                best_seq = best_seq[:-1]\n",
    "\n",
    "            # Add to results\n",
    "            results.append(torch.tensor(best_seq))\n",
    "\n",
    "        # Create padded tensor\n",
    "        max_len = max([len(seq) for seq in results]) if results else 0\n",
    "        padded_results = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
    "        for i, seq in enumerate(results):\n",
    "            end = len(seq)\n",
    "            padded_results[i, :end] = seq\n",
    "\n",
    "        return padded_results\n",
    "\n",
    "# Function to generate dummy data for testing the model\n",
    "def create_dummy_batch(batch_size=2, seq_len=10, vocab_size=100):\n",
    "    # Create dummy images\n",
    "    images = torch.randn(batch_size, 3, 224, 224)\n",
    "\n",
    "    # Create dummy captions\n",
    "    captions = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "    return images, captions\n",
    "\n",
    "# Main execution function\n",
    "def run(training_mode=False):\n",
    "    # Create dataset for training\n",
    "    print(\"Creating training dataset...\")\n",
    "    train_dataset = ChestXRayReportDataset(train_df, is_train=True, transform=transform)\n",
    "\n",
    "    # Build vocabulary - FIXED: Use the get_all_reports method\n",
    "    print(\"Building vocabulary...\")\n",
    "    vocab = Vocabulary()\n",
    "    # Get all reports from the dataset\n",
    "    all_reports = train_dataset.get_all_reports()\n",
    "    vocab.build_vocabulary(all_reports)\n",
    "    print(f\"Built vocabulary with {len(vocab)} tokens\")\n",
    "\n",
    "    # Save vocabulary\n",
    "    vocab_path = os.path.join(models_dir, 'vocab.pkl')\n",
    "    with open(vocab_path, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=0  # Set to 0 to avoid multiprocessing issues on Mac\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = CNNRNNModel(\n",
    "        vocab_size=len(vocab),\n",
    "        embed_size=256,\n",
    "        hidden_size=512,\n",
    "        cnn_feature_size=1024\n",
    "    )\n",
    "\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Test model with dummy data to verify dimensions\n",
    "    print(\"Testing model with dummy data...\")\n",
    "    dummy_images, dummy_captions = create_dummy_batch(batch_size=2, seq_len=10, vocab_size=len(vocab))\n",
    "    dummy_images = dummy_images.to(device)\n",
    "    dummy_captions = dummy_captions.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(dummy_images, dummy_captions)\n",
    "            print(f\"Dummy forward pass successful! Output shape: {outputs.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in dummy forward pass: {e}\")\n",
    "        return\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=16, gamma=0.5)  # LR decay every 16 epochs\n",
    "\n",
    "    # Load model path (but we won't load the model as requested)\n",
    "    model_path = os.path.join(models_dir, 'cnn_rnn_improved.pth')\n",
    "\n",
    "    if training_mode:\n",
    "        print(\"Training new model from scratch...\")\n",
    "        # Training loop\n",
    "        num_epochs = 64  # Change to 64 for full training\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "\n",
    "            # Gradually decrease teacher forcing\n",
    "            teacher_forcing_ratio = max(0.5 - (epoch // 16) * 0.1, 0.0)\n",
    "\n",
    "            for i, (images, captions, _) in enumerate(tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "                images = images.to(device)\n",
    "\n",
    "                # Tokenize and pad captions\n",
    "                tokenized_captions = []\n",
    "                for caption in captions:\n",
    "                    if caption:\n",
    "                        tokens = [1]  # < SOS >\n",
    "                        tokens.extend(vocab.numericalize(caption))\n",
    "                        tokens.append(2)  # <EOS>\n",
    "                    else:\n",
    "                        tokens = [1, 2]  # < SOS >, <EOS>\n",
    "                    tokenized_captions.append(tokens)\n",
    "\n",
    "                # Pad sequences\n",
    "                padded_captions = []\n",
    "                for tokens in tokenized_captions:\n",
    "                    if len(tokens) > 100:\n",
    "                        padded_captions.append(tokens[:100])\n",
    "                    else:\n",
    "                        padded_captions.append(tokens + [0] * (100 - len(tokens)))\n",
    "\n",
    "                captions_tensor = torch.tensor(padded_captions).to(device)\n",
    "\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images, captions_tensor, teacher_forcing_ratio)\n",
    "\n",
    "                # Reshape for loss calculation\n",
    "                outputs = outputs.reshape(-1, outputs.shape[2])\n",
    "                targets = captions_tensor.reshape(-1)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip gradients\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update training loss\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Print progress\n",
    "                if (i + 1) % 50 == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "                # Break after a few batches for testing\n",
    "                #if i >= 3:  # Remove this line for full training\n",
    "                #    break\n",
    "\n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "\n",
    "            # Calculate average loss for the epoch\n",
    "            avg_loss = train_loss / len(train_loader)  # Calculate average over all batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Teacher forcing: {teacher_forcing_ratio:.2f}\")\n",
    "\n",
    "            # Save model if it's the best so far\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"Model saved with improved loss: {best_loss:.4f}\")\n",
    "\n",
    "    # Create test dataset\n",
    "    print(\"Creating test dataset...\")\n",
    "    test_dataset = ChestXRayReportDataset(test_df, is_train=False, transform=transform)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,  # Process one at a time for generation\n",
    "        shuffle=False,\n",
    "        num_workers=0  # Set to 0 to avoid multiprocessing issues on Mac\n",
    "    )\n",
    "\n",
    "    # Generate reports using beam search\n",
    "    print(\"Generating reports using beam search...\")\n",
    "    model.eval()\n",
    "\n",
    "    generated_reports = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Process a few samples for demonstration\n",
    "        max_samples = 3\n",
    "        sample_count = 0\n",
    "\n",
    "        for images, dicom_ids in tqdm.tqdm(test_loader):\n",
    "            if sample_count >= max_samples:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            dicom_id = dicom_ids[0]  # Batch size is 1\n",
    "\n",
    "            try:\n",
    "                # Generate caption using beam search\n",
    "                outputs = model(images)  # Uses beam search by default\n",
    "\n",
    "                # Convert token indices to words\n",
    "                caption = []\n",
    "                for token_id in outputs[0]:\n",
    "                    token_id = token_id.item()\n",
    "                    if token_id == 2:  # <EOS>\n",
    "                        break\n",
    "                    if token_id > 3:  # Skip <PAD>, < SOS >, <EOS>, <UNK>\n",
    "                        caption.append(vocab.itos[token_id])\n",
    "\n",
    "                # Join words into a sentence, properly handling punctuation\n",
    "                report_text = \"\"\n",
    "                for word in caption:\n",
    "                    if word in string.punctuation:\n",
    "                        report_text += word\n",
    "                    else:\n",
    "                        if report_text and not report_text.endswith(' '):\n",
    "                            report_text += ' '\n",
    "                        report_text += word\n",
    "\n",
    "                generated_reports[dicom_id] = report_text\n",
    "\n",
    "                sample_count += 1\n",
    "                print(f\"Generated report {sample_count}/{max_samples}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating report for {dicom_id}: {e}\")\n",
    "\n",
    "    # Show sample reports\n",
    "    print(\"\\nSample generated reports:\")\n",
    "    for dicom_id, report in generated_reports.items():\n",
    "        print(f\"\\nDICOM ID: {dicom_id}\")\n",
    "        print(f\"Report: {report}\")\n",
    "\n",
    "    # Save generated reports\n",
    "    if generated_reports:\n",
    "        report_df = pd.DataFrame({\n",
    "            'dicom_id': list(generated_reports.keys()),\n",
    "            'generated': list(generated_reports.values())\n",
    "        })\n",
    "\n",
    "        output_file = os.path.join(output_dir, 'cnn_rnn_beam_search.tsv')\n",
    "        report_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"Generated {len(generated_reports)} reports and saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No reports were generated\")\n",
    "\n",
    "# For this example, setting training_mode to True to train a new model\n",
    "# Change to False to only generate reports using a pretrained model\n",
    "if __name__ == \"__main__\":\n",
    "    run(training_mode=True)"
   ],
   "id": "4b55b03349b3af96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported report parser module\n",
      "Train data shape: (4370, 3)\n",
      "Test data shape: (1688, 3)\n",
      "Using device: cpu\n",
      "Creating training dataset...\n",
      "Extracting report texts for training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4370/4370 [00:01<00:00, 2950.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 4362 reports from training data\n",
      "Building vocabulary...\n",
      "Top 20 most frequent words:\n",
      ".: 24934\n",
      "the: 15302\n",
      "is: 12317\n",
      ",: 5867\n",
      "no: 4919\n",
      "are: 4840\n",
      "there: 4762\n",
      "of: 4663\n",
      "right: 4461\n",
      "and: 4139\n",
      "in: 3957\n",
      "left: 3548\n",
      "pleural: 3147\n",
      "pneumothorax: 3025\n",
      "effusion: 2869\n",
      "lung: 2539\n",
      "to: 2499\n",
      "a: 2433\n",
      "with: 2416\n",
      "or: 2239\n",
      "Built vocabulary with 1925 tokens\n",
      "Loading DenseNet121 model with pretrained weights...\n",
      "Testing model with dummy data...\n",
      "Dummy forward pass successful! Output shape: torch.Size([2, 10, 1925])\n",
      "Training new model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/64:  36%|███▋      | 50/137 [08:17<14:34, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/64], Step [50/137], Loss: 4.2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/64:  73%|███████▎  | 100/137 [16:56<06:18, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/64], Step [100/137], Loss: 3.3553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/64: 100%|██████████| 137/137 [23:11<00:00, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/64], Loss: 3.8802, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 3.8802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/64:  36%|███▋      | 50/137 [08:06<13:53,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/64], Step [50/137], Loss: 2.7814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/64:  73%|███████▎  | 100/137 [15:05<04:58,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/64], Step [100/137], Loss: 2.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/64: 100%|██████████| 137/137 [20:07<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/64], Loss: 2.5424, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 2.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/64:  36%|███▋      | 50/137 [07:01<12:00,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/64], Step [50/137], Loss: 2.3667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/64:  73%|███████▎  | 100/137 [13:51<05:02,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/64], Step [100/137], Loss: 1.7809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/64: 100%|██████████| 137/137 [19:04<00:00,  8.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/64], Loss: 2.2265, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 2.2265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/64:  36%|███▋      | 50/137 [06:46<14:39, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/64], Step [50/137], Loss: 2.3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/64:  73%|███████▎  | 100/137 [13:12<04:50,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/64], Step [100/137], Loss: 2.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/64: 100%|██████████| 137/137 [17:59<00:00,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/64], Loss: 2.0461, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 2.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/64:  36%|███▋      | 50/137 [06:30<11:17,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/64], Step [50/137], Loss: 2.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/64:  73%|███████▎  | 100/137 [12:45<04:41,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/64], Step [100/137], Loss: 1.9434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/64: 100%|██████████| 137/137 [17:35<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/64], Loss: 2.0028, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 2.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/64:  36%|███▋      | 50/137 [06:30<11:19,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/64], Step [50/137], Loss: 1.8146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/64:  73%|███████▎  | 100/137 [12:53<04:36,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/64], Step [100/137], Loss: 1.6385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/64: 100%|██████████| 137/137 [17:38<00:00,  7.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/64], Loss: 1.9508, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.9508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/64:  36%|███▋      | 50/137 [06:33<11:41,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/64], Step [50/137], Loss: 2.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/64:  73%|███████▎  | 100/137 [12:51<04:34,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/64], Step [100/137], Loss: 1.9054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/64: 100%|██████████| 137/137 [17:28<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/64], Loss: 1.8939, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/64:  36%|███▋      | 50/137 [06:33<11:21,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/64], Step [50/137], Loss: 2.1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/64:  73%|███████▎  | 100/137 [12:58<04:35,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/64], Step [100/137], Loss: 2.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/64: 100%|██████████| 137/137 [17:28<00:00,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/64], Loss: 1.8912, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/64:  36%|███▋      | 50/137 [06:32<11:16,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/64], Step [50/137], Loss: 1.7195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/64:  73%|███████▎  | 100/137 [13:02<04:49,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/64], Step [100/137], Loss: 1.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/64: 100%|██████████| 137/137 [17:35<00:00,  7.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/64], Loss: 1.8129, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/64:  36%|███▋      | 50/137 [06:26<11:17,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/64], Step [50/137], Loss: 1.6728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/64:  73%|███████▎  | 100/137 [12:56<04:48,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/64], Step [100/137], Loss: 1.1948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/64: 100%|██████████| 137/137 [17:39<00:00,  7.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/64], Loss: 1.7681, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.7681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/64:  36%|███▋      | 50/137 [06:24<11:42,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/64], Step [50/137], Loss: 2.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/64:  73%|███████▎  | 100/137 [13:01<04:52,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/64], Step [100/137], Loss: 1.7048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/64: 100%|██████████| 137/137 [17:51<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/64], Loss: 1.7632, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/64:  36%|███▋      | 50/137 [06:19<11:35,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/64], Step [50/137], Loss: 1.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/64:  73%|███████▎  | 100/137 [12:58<04:52,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/64], Step [100/137], Loss: 2.3188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/64: 100%|██████████| 137/137 [17:47<00:00,  7.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/64], Loss: 1.7367, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/64:  36%|███▋      | 50/137 [06:15<10:50,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/64], Step [50/137], Loss: 2.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/64:  73%|███████▎  | 100/137 [12:53<04:54,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/64], Step [100/137], Loss: 2.3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/64: 100%|██████████| 137/137 [17:42<00:00,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/64], Loss: 1.7240, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/64:  36%|███▋      | 50/137 [06:28<11:36,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/64], Step [50/137], Loss: 1.2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/64:  73%|███████▎  | 100/137 [13:26<05:10,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/64], Step [100/137], Loss: 1.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/64: 100%|██████████| 137/137 [18:32<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/64], Loss: 1.7002, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/64:  36%|███▋      | 50/137 [06:45<11:17,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/64], Step [50/137], Loss: 1.6734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/64:  73%|███████▎  | 100/137 [13:37<05:11,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/64], Step [100/137], Loss: 1.3075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/64: 100%|██████████| 137/137 [18:43<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/64], Loss: 1.6965, Teacher forcing: 0.50\n",
      "Model saved with improved loss: 1.6965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/64:  36%|███▋      | 50/137 [06:50<11:41,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/64], Step [50/137], Loss: 2.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/64:  73%|███████▎  | 100/137 [13:41<05:09,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/64], Step [100/137], Loss: 1.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/64: 100%|██████████| 137/137 [18:49<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/64], Loss: 1.7224, Teacher forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/64:  36%|███▋      | 50/137 [06:49<11:30,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/64], Step [50/137], Loss: 2.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/64:  73%|███████▎  | 100/137 [13:20<04:57,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/64], Step [100/137], Loss: 1.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/64: 100%|██████████| 137/137 [18:06<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/64], Loss: 2.1664, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/64:  36%|███▋      | 50/137 [06:28<10:47,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/64], Step [50/137], Loss: 1.4739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/64:  73%|███████▎  | 100/137 [12:41<04:45,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/64], Step [100/137], Loss: 2.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/64: 100%|██████████| 137/137 [17:27<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/64], Loss: 2.1131, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/64:  36%|███▋      | 50/137 [06:30<11:20,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/64], Step [50/137], Loss: 2.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/64:  73%|███████▎  | 100/137 [12:44<04:31,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/64], Step [100/137], Loss: 2.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/64: 100%|██████████| 137/137 [17:28<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/64], Loss: 2.1665, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/64:  36%|███▋      | 50/137 [06:31<11:23,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/64], Step [50/137], Loss: 2.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/64:  73%|███████▎  | 100/137 [12:54<04:35,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/64], Step [100/137], Loss: 2.2655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/64: 100%|██████████| 137/137 [17:34<00:00,  7.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/64], Loss: 2.1050, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/64:  36%|███▋      | 50/137 [06:31<11:22,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/64], Step [50/137], Loss: 2.3564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/64:  73%|███████▎  | 100/137 [13:15<04:53,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/64], Step [100/137], Loss: 2.5915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/64: 100%|██████████| 137/137 [18:12<00:00,  7.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/64], Loss: 2.1106, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/64:  36%|███▋      | 50/137 [07:00<12:12,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/64], Step [50/137], Loss: 1.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/64:  73%|███████▎  | 100/137 [13:56<04:55,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/64], Step [100/137], Loss: 1.8214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/64: 100%|██████████| 137/137 [18:51<00:00,  8.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/64], Loss: 2.0972, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/64:  36%|███▋      | 50/137 [07:01<12:11,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/64], Step [50/137], Loss: 1.6776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/64:  73%|███████▎  | 100/137 [13:56<04:52,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/64], Step [100/137], Loss: 2.1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/64: 100%|██████████| 137/137 [18:49<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/64], Loss: 2.0264, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/64:  36%|███▋      | 50/137 [07:01<12:09,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/64], Step [50/137], Loss: 2.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/64:  73%|███████▎  | 100/137 [13:53<04:30,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/64], Step [100/137], Loss: 2.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/64: 100%|██████████| 137/137 [18:26<00:00,  8.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/64], Loss: 2.0702, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/64:  36%|███▋      | 50/137 [06:35<12:07,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/64], Step [50/137], Loss: 2.2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/64:  73%|███████▎  | 100/137 [13:39<05:15,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/64], Step [100/137], Loss: 1.8366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/64: 100%|██████████| 137/137 [18:25<00:00,  8.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/64], Loss: 2.0940, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/64:  36%|███▋      | 50/137 [06:48<11:48,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/64], Step [50/137], Loss: 1.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/64:  73%|███████▎  | 100/137 [13:45<05:08,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/64], Step [100/137], Loss: 2.2272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/64: 100%|██████████| 137/137 [18:35<00:00,  8.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/64], Loss: 2.0962, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/64:  36%|███▋      | 50/137 [06:47<11:52,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/64], Step [50/137], Loss: 2.0933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/64:  73%|███████▎  | 100/137 [13:44<04:58,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/64], Step [100/137], Loss: 1.8536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/64: 100%|██████████| 137/137 [18:40<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/64], Loss: 2.0409, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/64:  36%|███▋      | 50/137 [06:48<12:56,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/64], Step [50/137], Loss: 2.2824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/64:  73%|███████▎  | 100/137 [13:50<04:53,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/64], Step [100/137], Loss: 2.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/64: 100%|██████████| 137/137 [18:33<00:00,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/64], Loss: 2.0489, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/64:  36%|███▋      | 50/137 [06:29<12:18,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/64], Step [50/137], Loss: 1.9542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/64:  73%|███████▎  | 100/137 [13:09<04:55,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/64], Step [100/137], Loss: 2.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/64: 100%|██████████| 137/137 [17:56<00:00,  7.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/64], Loss: 2.0453, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/64:  36%|███▋      | 50/137 [06:10<11:08,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/64], Step [50/137], Loss: 1.6681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/64:  73%|███████▎  | 100/137 [12:44<04:54,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/64], Step [100/137], Loss: 2.3520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/64: 100%|██████████| 137/137 [17:30<00:00,  7.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/64], Loss: 2.0092, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/64:  36%|███▋      | 50/137 [06:12<10:47,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/64], Step [50/137], Loss: 1.8406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/64:  73%|███████▎  | 100/137 [12:42<04:52,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/64], Step [100/137], Loss: 1.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/64: 100%|██████████| 137/137 [17:29<00:00,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/64], Loss: 2.0189, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/64:  36%|███▋      | 50/137 [06:18<10:46,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/64], Step [50/137], Loss: 1.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/64:  73%|███████▎  | 100/137 [12:45<04:49,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/64], Step [100/137], Loss: 1.5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/64: 100%|██████████| 137/137 [17:32<00:00,  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/64], Loss: 2.0473, Teacher forcing: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/64:  36%|███▋      | 50/137 [06:26<10:49,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/64], Step [50/137], Loss: 2.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/64:  73%|███████▎  | 100/137 [12:49<04:48,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/64], Step [100/137], Loss: 2.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/64: 100%|██████████| 137/137 [17:38<00:00,  7.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/64], Loss: 2.6422, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/64:  36%|███▋      | 50/137 [06:53<11:24,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/64], Step [50/137], Loss: 2.2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/64:  73%|███████▎  | 100/137 [13:43<05:15,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/64], Step [100/137], Loss: 2.0883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/64: 100%|██████████| 137/137 [18:54<00:00,  8.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/64], Loss: 2.6263, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/64:  36%|███▋      | 50/137 [06:55<11:15,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/64], Step [50/137], Loss: 2.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/64:  73%|███████▎  | 100/137 [13:41<05:12,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/64], Step [100/137], Loss: 1.8503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/64: 100%|██████████| 137/137 [18:56<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/64], Loss: 2.5869, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/64:  36%|███▋      | 50/137 [06:58<11:19,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/64], Step [50/137], Loss: 2.4964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/64:  73%|███████▎  | 100/137 [13:39<05:09,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/64], Step [100/137], Loss: 2.8879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/64: 100%|██████████| 137/137 [18:46<00:00,  8.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/64], Loss: 2.5851, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/64:  36%|███▋      | 50/137 [06:45<11:21,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/64], Step [50/137], Loss: 2.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/64:  73%|███████▎  | 100/137 [12:57<04:38,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/64], Step [100/137], Loss: 2.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/64: 100%|██████████| 137/137 [17:44<00:00,  7.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/64], Loss: 2.5719, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/64:  36%|███▋      | 50/137 [06:37<12:32,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/64], Step [50/137], Loss: 2.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/64:  73%|███████▎  | 100/137 [13:05<04:39,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/64], Step [100/137], Loss: 2.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/64: 100%|██████████| 137/137 [17:50<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/64], Loss: 2.5359, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/64:  36%|███▋      | 50/137 [06:41<12:30,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/64], Step [50/137], Loss: 3.3804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/64:  73%|███████▎  | 100/137 [13:10<04:46,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/64], Step [100/137], Loss: 2.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/64: 100%|██████████| 137/137 [18:02<00:00,  7.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/64], Loss: 2.5398, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/64:  36%|███▋      | 50/137 [06:39<11:45,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/64], Step [50/137], Loss: 2.4646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/64:  73%|███████▎  | 100/137 [13:08<04:36,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/64], Step [100/137], Loss: 2.2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/64: 100%|██████████| 137/137 [17:47<00:00,  7.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/64], Loss: 2.5828, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/64:  36%|███▋      | 50/137 [06:30<11:28,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/64], Step [50/137], Loss: 2.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/64:  73%|███████▎  | 100/137 [12:52<04:27,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/64], Step [100/137], Loss: 3.3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/64: 100%|██████████| 137/137 [17:19<00:00,  7.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/64], Loss: 2.5816, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/64:  36%|███▋      | 50/137 [06:26<11:25,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/64], Step [50/137], Loss: 2.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/64:  73%|███████▎  | 100/137 [12:51<04:43,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/64], Step [100/137], Loss: 2.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/64: 100%|██████████| 137/137 [17:20<00:00,  7.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/64], Loss: 2.5400, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/64:  36%|███▋      | 50/137 [06:21<11:09,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/64], Step [50/137], Loss: 2.3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/64:  73%|███████▎  | 100/137 [12:56<04:49,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/64], Step [100/137], Loss: 2.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/64: 100%|██████████| 137/137 [17:36<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/64], Loss: 2.5598, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/64:  36%|███▋      | 50/137 [06:22<11:41,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/64], Step [50/137], Loss: 2.2564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/64:  73%|███████▎  | 100/137 [13:15<05:07,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/64], Step [100/137], Loss: 2.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/64: 100%|██████████| 137/137 [18:13<00:00,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/64], Loss: 2.5840, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/64:  36%|███▋      | 50/137 [06:23<11:26,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/64], Step [50/137], Loss: 1.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/64:  73%|███████▎  | 100/137 [13:14<05:15,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/64], Step [100/137], Loss: 2.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/64: 100%|██████████| 137/137 [18:14<00:00,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/64], Loss: 2.5812, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/64:  36%|███▋      | 50/137 [06:42<11:07,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/64], Step [50/137], Loss: 2.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/64:  73%|███████▎  | 100/137 [13:25<04:59,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/64], Step [100/137], Loss: 2.4689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/64: 100%|██████████| 137/137 [18:22<00:00,  8.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/64], Loss: 2.5257, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/64:  36%|███▋      | 50/137 [06:31<11:06,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/64], Step [50/137], Loss: 2.4304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/64:  73%|███████▎  | 100/137 [13:11<04:59,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/64], Step [100/137], Loss: 2.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/64: 100%|██████████| 137/137 [18:07<00:00,  7.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/64], Loss: 2.5600, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/64:  36%|███▋      | 50/137 [06:36<11:02,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/64], Step [50/137], Loss: 2.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/64:  73%|███████▎  | 100/137 [13:19<05:02,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/64], Step [100/137], Loss: 2.3207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/64: 100%|██████████| 137/137 [18:17<00:00,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/64], Loss: 2.5992, Teacher forcing: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/64:  36%|███▋      | 50/137 [06:36<11:12,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/64], Step [50/137], Loss: 3.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/64:  73%|███████▎  | 100/137 [13:05<05:06,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/64], Step [100/137], Loss: 3.3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/64: 100%|██████████| 137/137 [18:03<00:00,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/64], Loss: 3.2525, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/64:  36%|███▋      | 50/137 [06:49<12:04,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/64], Step [50/137], Loss: 3.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/64:  73%|███████▎  | 100/137 [13:15<04:57,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/64], Step [100/137], Loss: 3.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/64: 100%|██████████| 137/137 [18:18<00:00,  8.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/64], Loss: 3.2070, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/64:  36%|███▋      | 50/137 [06:45<11:49,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/64], Step [50/137], Loss: 3.2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/64:  73%|███████▎  | 100/137 [13:11<04:45,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/64], Step [100/137], Loss: 3.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/64: 100%|██████████| 137/137 [18:13<00:00,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/64], Loss: 3.2482, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/64:  36%|███▋      | 50/137 [06:47<11:54,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/64], Step [50/137], Loss: 2.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/64:  73%|███████▎  | 100/137 [13:19<04:45,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/64], Step [100/137], Loss: 3.4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/64: 100%|██████████| 137/137 [18:19<00:00,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/64], Loss: 3.2623, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/64:  36%|███▋      | 50/137 [06:42<11:39,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/64], Step [50/137], Loss: 3.4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/64:  73%|███████▎  | 100/137 [13:28<04:40,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/64], Step [100/137], Loss: 3.5385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/64: 100%|██████████| 137/137 [18:20<00:00,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/64], Loss: 3.2290, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/64:  36%|███▋      | 50/137 [07:07<11:51,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/64], Step [50/137], Loss: 3.2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/64:  73%|███████▎  | 100/137 [13:49<04:32,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/64], Step [100/137], Loss: 2.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/64: 100%|██████████| 137/137 [18:23<00:00,  8.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/64], Loss: 3.2797, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/64:  36%|███▋      | 50/137 [06:36<11:25,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/64], Step [50/137], Loss: 3.8555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/64:  73%|███████▎  | 100/137 [13:09<04:51,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/64], Step [100/137], Loss: 3.4029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/64: 100%|██████████| 137/137 [17:40<00:00,  7.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/64], Loss: 3.1896, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/64:  36%|███▋      | 50/137 [06:35<11:23,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/64], Step [50/137], Loss: 3.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/64:  73%|███████▎  | 100/137 [13:08<04:50,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/64], Step [100/137], Loss: 3.8957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/64: 100%|██████████| 137/137 [17:43<00:00,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/64], Loss: 3.2369, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/64:  36%|███▋      | 50/137 [06:31<11:44,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/64], Step [50/137], Loss: 3.4469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/64:  73%|███████▎  | 100/137 [13:03<04:50,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/64], Step [100/137], Loss: 3.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/64: 100%|██████████| 137/137 [17:40<00:00,  7.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/64], Loss: 3.1807, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/64:  36%|███▋      | 50/137 [06:28<13:13,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/64], Step [50/137], Loss: 3.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/64:  73%|███████▎  | 100/137 [13:03<04:50,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/64], Step [100/137], Loss: 3.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/64: 100%|██████████| 137/137 [17:51<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/64], Loss: 3.2704, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/64:  36%|███▋      | 50/137 [06:14<11:16,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/64], Step [50/137], Loss: 3.4476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/64:  73%|███████▎  | 100/137 [12:51<04:53,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/64], Step [100/137], Loss: 3.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/64: 100%|██████████| 137/137 [17:40<00:00,  7.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/64], Loss: 3.2095, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/64:  36%|███▋      | 50/137 [06:14<10:44,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/64], Step [50/137], Loss: 3.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/64:  73%|███████▎  | 100/137 [12:43<04:49,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/64], Step [100/137], Loss: 3.1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/64: 100%|██████████| 137/137 [17:31<00:00,  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/64], Loss: 3.2511, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/64:  36%|███▋      | 50/137 [06:23<10:46,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/64], Step [50/137], Loss: 3.3110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/64:  73%|███████▎  | 100/137 [12:49<04:50,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/64], Step [100/137], Loss: 3.5716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/64: 100%|██████████| 137/137 [17:36<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/64], Loss: 3.2161, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/64:  36%|███▋      | 50/137 [06:25<11:01,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/64], Step [50/137], Loss: 3.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/64:  73%|███████▎  | 100/137 [13:01<05:14,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/64], Step [100/137], Loss: 3.2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/64: 100%|██████████| 137/137 [18:09<00:00,  7.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/64], Loss: 3.2076, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/64:  36%|███▋      | 50/137 [06:54<11:25,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/64], Step [50/137], Loss: 3.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/64:  73%|███████▎  | 100/137 [13:30<05:02,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/64], Step [100/137], Loss: 3.6753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/64: 100%|██████████| 137/137 [18:42<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/64], Loss: 3.2136, Teacher forcing: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/64:  36%|███▋      | 50/137 [07:04<12:22,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/64], Step [50/137], Loss: 3.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/64:  73%|███████▎  | 100/137 [13:42<04:48,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/64], Step [100/137], Loss: 2.8529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/64: 100%|██████████| 137/137 [18:33<00:00,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/64], Loss: 3.2178, Teacher forcing: 0.20\n",
      "Creating test dataset...\n",
      "Generating reports using beam search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1688 [00:00<03:53,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report 1/3\n",
      "Generated report 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1688 [00:00<04:28,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report 3/3\n",
      "\n",
      "Sample generated reports:\n",
      "\n",
      "DICOM ID: b8e14e3b-545cd663-a00812c0-9e772d64-b3d40e32\n",
      "Report: portable portable upright view of the chest. there ekg leads are present. the lungs lungs appear appear clear without without focal or or pneumothorax effusion effusion\n",
      "\n",
      "DICOM ID: 8c295118-0d590369-21de2213-312374d8-50c8a349\n",
      "Report: portable portable upright view of the chest. there ekg leads are present. the lungs lungs appear appear clear without without focal or or pneumothorax effusion effusion\n",
      "\n",
      "DICOM ID: fc75e61c-ee134385-a5d0e01b-695f8125-2ed13ad2\n",
      "Report: portable portable upright view of the chest. there ekg leads are present. the lungs lungs appear appear clear without without focal or or pneumothorax effusion effusion\n",
      "Generated 3 reports and saved to /Users/simeon/Documents/DLH/content/mimic-cxr-project/output/cnn_rnn_beam_search.tsv\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 9
}
